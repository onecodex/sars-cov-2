{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "from altair_saver import save\n",
    "from Bio import SeqIO\n",
    "from IPython.display import HTML\n",
    "from onecodex import Api\n",
    "from onecodex.notebooks.report import set_style, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocx = Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = os.environ.get(\"ONE_CODEX_REPORT_ENV\", \"draft\")\n",
    "\n",
    "if ENVIRONMENT == \"production\":\n",
    "    sample_uuid = os.environ[\"ONE_CODEX_SAMPLE_UUID\"]\n",
    "else:\n",
    "    sample_uuid = None\n",
    "    sample_filename = \"sample.fastq\"\n",
    "    \n",
    "sample = ocx.Samples.get(sample_uuid)    \n",
    "\n",
    "assert sample is not None, \"Sample does not exist\"\n",
    "sample_filename = sample.filename\n",
    "if not os.path.exists(sample_filename):\n",
    "    sample.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output paths\n",
    "VARIANTS_TSV_PATH = \"variants.tsv\"\n",
    "NEXTCLADE_JSON = \"nextclade.json\"\n",
    "NEXTCLADE_TSV_PATH = \"nextclade.tsv\"\n",
    "PANGOLIN_CSV_PATH = \"pangolin.csv\"\n",
    "BAM_PATH = \"covid19.bam\"\n",
    "CONSENSUS_PATH = \"consensus.fa\"\n",
    "\n",
    "# input paths\n",
    "REFERENCE_PATH = os.environ.get(\n",
    "    \"FASTA_REFERENCE\", \"/share/nCoV-2019.reference.fasta\"\n",
    ")\n",
    "\n",
    "# default illumina + ivar pipeline\n",
    "BED_FILE_PATH = os.environ.get(\"BED_FILE_PATH\", \"/share/ARTIC-V1.bed\")\n",
    "REFERENCE_NAME = os.path.basename(REFERENCE_PATH).rstrip('.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"SEQUENCING_PLATFORM\") == \"Oxford Nanopore\":\n",
    "#     print(\"Using ONT ARTIC v3 pipeline to call variants\")\n",
    "    MIN_DEPTH = 50\n",
    "    !/usr/local/bin/covid19_call_variants.artic.sh {sample_filename} > variants.log 2>&1\n",
    "else:\n",
    "#     print(\"Using short-read ARTIC v1 pipeline to call variants\")\n",
    "    MIN_DEPTH = 10\n",
    "    !/usr/local/bin/covid19_call_variants.sh {REFERENCE_PATH} {sample_filename} {BED_FILE_PATH} > variants.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before proceeding, do QC on the consensus sequence.\n",
    "\n",
    "# 1. Error if the consensus sequence length is full of N's\n",
    "error_messages = []\n",
    "for record in SeqIO.parse(CONSENSUS_PATH, \"fasta\"):\n",
    "    if record.seq.count(\"N\") > 20000:\n",
    "        error_messages.append(\"The consensus sequence has too many ambiguous bases: \" + str(record.seq.count(\"N\")) + \" N's against the 29,903 base reference sequence.\")\n",
    "\n",
    "# 2. Error if there is no stretch of unambiguous bases >10kb\n",
    "# This crazy seqkit/awk command will split the fasta whenever a string of ambiguous bases (N/n's) appears,\n",
    "# and produces \"consensus.contigs.fa\" where each contig is a stretch of unambiguous bases.\n",
    "!seqkit seq -w0 consensus.fa | awk '{gsub(\"[Nn]+\",\"\\n>\\n\");}1' | awk '/^>/ {if ($0 == \">\") {$0=prev} prev=$0}1' | awk '/^>/ {getline seq} {if(seq!=\"\") {print $0\"\\n\"seq}}' | awk '(/^>/ && a[$0]++) {$0=$0\"_\"a[$0]}1' > consensus.contigs.fa\n",
    "\n",
    "# Get the length of the longest stretch of unambiguous bases.\n",
    "max_unambig_len = 0\n",
    "if os.path.getsize(\"consensus.contigs.fa\") != 0:\n",
    "    for record in SeqIO.parse(\"consensus.contigs.fa\", \"fasta\"):\n",
    "        if len(record.seq) > max_unambig_len:\n",
    "            max_unambig_len = len(record.seq)\n",
    "        \n",
    "if max_unambig_len < 10000:\n",
    "    error_messages.append(\"The consensus sequence is too incomplete for GISAID submission (the longest stretch of unambiguous bases must be over 10,000).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process variants\n",
    "!post_process_variants.sh consensus.fa > variants.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference genome\n",
    "reference = list(SeqIO.parse(REFERENCE_PATH, \"fasta\"))\n",
    "reference_length = len(reference[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools depth $BAM_PATH > snps.depth 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reads = sample.primary_classification.results()[\"n_reads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools_view_output = !samtools view -F 2308 $BAM_PATH | wc -l\n",
    "n_mapped_reads = int(samtools_view_output[0])\n",
    "proportion_mapped_reads = n_mapped_reads / n_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_table = []\n",
    "\n",
    "with open(\"snps.depth\") as handle:\n",
    "    for line in handle:\n",
    "        row = line.strip().split(\"\\t\")\n",
    "        depth_table.append(\n",
    "            {\"reference\": row[0], \"position\": int(row[1]), \"depth\": int(row[2])}\n",
    "        )\n",
    "depth_table = pd.DataFrame(depth_table, columns=[\"reference\", \"position\", \"depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate genome coverage (what percent of bases are coveraged at X coverage)\n",
    "# Use a fixed reference length that we use for `samtools depth` above\n",
    "\n",
    "covered_sites = set()\n",
    "covered_sites_mindepth = set()\n",
    "\n",
    "for _, row in depth_table.iterrows():\n",
    "    row = row.to_dict()\n",
    "    if row[\"depth\"] >= 1:\n",
    "        covered_sites.add(row[\"position\"])\n",
    "    if row[\"depth\"] >= MIN_DEPTH:\n",
    "        covered_sites_mindepth.add(row[\"position\"])        \n",
    "\n",
    "cov = len(covered_sites) / reference_length\n",
    "if cov <= 0.9:\n",
    "    error_messages.append(\"The consensus sequence is too incomplete for GISAID submission (reads must span >90% of the reference).\")\n",
    "cov_mindepth = len(covered_sites_mindepth) / reference_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reference_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a7fdb7c2f5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get mean over windows because altair can't handle > 5k points ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbinned_depths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwindow_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reference_length' is not defined"
     ]
    }
   ],
   "source": [
    "# get mean over windows because altair can't handle > 5k points ...\n",
    "binned_depths = []\n",
    "window_width = reference_length // 4500\n",
    "\n",
    "for i in range(1, reference_length, window_width):\n",
    "    window = depth_table.loc[\n",
    "        (depth_table[\"position\"] > i) & (depth_table[\"position\"] < i + window_width)\n",
    "    ]\n",
    "\n",
    "    binned_depths.append(\n",
    "        {\"position\": i, \"depth\": window[\"depth\"].mean(),}\n",
    "    )\n",
    "\n",
    "binned_depths = pd.DataFrame(binned_depths)\n",
    "# Convert position from bp to kbp, to improve how the coverage plot looks\n",
    "binned_depths[\"position\"] = binned_depths[\"position\"]/1000\n",
    "mean_depth = depth_table[\"depth\"].mean() if not depth_table.empty else 0\n",
    "median_depth = depth_table[\"depth\"].median() if not depth_table.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Nextclade and Pangolin tables\n",
    "\n",
    "# Don't need to read table; can get all info from Nextclade json\n",
    "#nextclade_table = pd.read_csv(NEXTCLADE_TSV_PATH, sep=\"\\t\")\n",
    "pangolin_table = pd.read_csv(PANGOLIN_CSV_PATH, sep=\",\")\n",
    "\n",
    "# Add to results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nextclade JSON\n",
    "##### Please note that everything in the Nextclade JSON (nt positions, ranges, codon positions) is 0-indexed,\n",
    "##### but SARS-CoV-2 variants (and most things) are reported as 1-indexed.\n",
    "\n",
    "#with open(NEXTCLADE_JSON) as json_file:\n",
    "with open(\"nextclade.json\") as json_file:\n",
    "    nextclade_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate warnings if indels are detected? (ONT does not reliably detect these)\n",
    "warnings = []\n",
    "if nextclade_json['insertions'] != []:\n",
    "    warnings.append('Insertions are detected.')\n",
    "if nextclade_json['deletions'] != []:\n",
    "    warnings.append('Deletions are detected.')\n",
    "if warnings != []:\n",
    "    for warning in warnings:\n",
    "        display(warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate variants table\n",
    "rows_list = []\n",
    "for subst in nextclade_json['substitutions']: # Each substitution is a dictionary\n",
    "    dict1 = {}\n",
    "    dict1['Position'] = subst['pos'] + 1 # JSON positions are 0-indexed; convert to 1-index\n",
    "    dict1['Ref'] = subst['refNuc']\n",
    "    dict1['Alt'] = subst['queryNuc']\n",
    "    if len(subst['aaSubstitutions']) != 0:\n",
    "        for mutation in subst['aaSubstitutions']: # JSON codons are 0-indexed; convert to 1-index\n",
    "            dict1['Amino acid mutation'] = mutation['refAA'] + str(mutation['codon']+1) + mutation['queryAA']\n",
    "    else:\n",
    "        dict1['Amino acid mutation'] = ''\n",
    "    rows_list.append(dict1)\n",
    "\n",
    "variant_table = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in gene info\n",
    "df_orfs = pd.read_csv(\"./annot_table.orfs.txt\", \\\n",
    "    sep=\"\\t\", \\\n",
    "    header=None, \\\n",
    "    usecols=[0, 1, 2], \\\n",
    "    names=[\"gene\", \"start\", \"stop\"])\n",
    "\n",
    "for i in variant_table.index:\n",
    "    for j in df_orfs.index:\n",
    "        if df_orfs.loc[j, \"start\"] <= variant_table.loc[i, \"Position\"] <= df_orfs.loc[j, \"stop\"]:\n",
    "            variant_table.loc[i, \"Gene\"] = df_orfs.loc[j, \"gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ref</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Alt depth</th>\n",
       "      <th>Total depth</th>\n",
       "      <th>Alt frequency (%)</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Amino acid mutation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>311</td>\n",
       "      <td>313</td>\n",
       "      <td>99.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>392</td>\n",
       "      <td>396</td>\n",
       "      <td>99.0</td>\n",
       "      <td>nsp2 in orf1ab</td>\n",
       "      <td>T265I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>nsp2 in orf1ab</td>\n",
       "      <td>V365I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>291</td>\n",
       "      <td>294</td>\n",
       "      <td>99.0</td>\n",
       "      <td>nsp2 in orf1ab</td>\n",
       "      <td>R724S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>99.3</td>\n",
       "      <td>nsp3 in orf1ab</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>382</td>\n",
       "      <td>386</td>\n",
       "      <td>99.0</td>\n",
       "      <td>nsp3 in orf1ab</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>343</td>\n",
       "      <td>352</td>\n",
       "      <td>97.4</td>\n",
       "      <td>nsp3 in orf1ab</td>\n",
       "      <td>M2606I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>358</td>\n",
       "      <td>379</td>\n",
       "      <td>94.5</td>\n",
       "      <td>nsp5 in orf1ab</td>\n",
       "      <td>L3352F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>287</td>\n",
       "      <td>288</td>\n",
       "      <td>99.7</td>\n",
       "      <td>nsp8 in orf1ab</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13201</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>386</td>\n",
       "      <td>387</td>\n",
       "      <td>99.7</td>\n",
       "      <td>nsp10 in orf1ab</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>192</td>\n",
       "      <td>199</td>\n",
       "      <td>96.5</td>\n",
       "      <td>nsp12 in orf1ab</td>\n",
       "      <td>P314L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14805</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>308</td>\n",
       "      <td>311</td>\n",
       "      <td>99.0</td>\n",
       "      <td>nsp12 in orf1ab</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16748</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>102</td>\n",
       "      <td>104</td>\n",
       "      <td>98.1</td>\n",
       "      <td>nsp13 in orf1ab</td>\n",
       "      <td>K1094R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18424</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>395</td>\n",
       "      <td>397</td>\n",
       "      <td>99.5</td>\n",
       "      <td>nsp14 in orf1ab</td>\n",
       "      <td>N1653D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19180</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>376</td>\n",
       "      <td>377</td>\n",
       "      <td>99.7</td>\n",
       "      <td>nsp14 in orf1ab</td>\n",
       "      <td>V1905L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>100</td>\n",
       "      <td>nsp16 in orf1ab</td>\n",
       "      <td>R2613C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23403</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>348</td>\n",
       "      <td>352</td>\n",
       "      <td>98.9</td>\n",
       "      <td>spike</td>\n",
       "      <td>D614G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24034</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>389</td>\n",
       "      <td>396</td>\n",
       "      <td>98.2</td>\n",
       "      <td>spike</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25563</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>99.4</td>\n",
       "      <td>orf3A</td>\n",
       "      <td>Q57H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25907</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>99.5</td>\n",
       "      <td>orf3A</td>\n",
       "      <td>G172V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27964</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>100</td>\n",
       "      <td>orf8</td>\n",
       "      <td>S24L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28472</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>150</td>\n",
       "      <td>154</td>\n",
       "      <td>97.4</td>\n",
       "      <td>geneN</td>\n",
       "      <td>P67S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28869</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>234</td>\n",
       "      <td>240</td>\n",
       "      <td>97.5</td>\n",
       "      <td>geneN</td>\n",
       "      <td>P199L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ref Alt Alt depth Total depth Alt frequency (%)             Gene  \\\n",
       "Position                                                                    \n",
       "241        C   T       311         313              99.4                    \n",
       "1059       C   T       392         396              99.0   nsp2 in orf1ab   \n",
       "1358       G   A        25          25               100   nsp2 in orf1ab   \n",
       "2437       A   T       291         294              99.0   nsp2 in orf1ab   \n",
       "3037       C   T       152         153              99.3   nsp3 in orf1ab   \n",
       "4633       C   T       382         386              99.0   nsp3 in orf1ab   \n",
       "8083       G   A       343         352              97.4   nsp3 in orf1ab   \n",
       "10319      C   T       358         379              94.5   nsp5 in orf1ab   \n",
       "12473      C   T       287         288              99.7   nsp8 in orf1ab   \n",
       "13201      G   T       386         387              99.7  nsp10 in orf1ab   \n",
       "14408      C   T       192         199              96.5  nsp12 in orf1ab   \n",
       "14805      C   T       308         311              99.0  nsp12 in orf1ab   \n",
       "16748      A   G       102         104              98.1  nsp13 in orf1ab   \n",
       "18424      A   G       395         397              99.5  nsp14 in orf1ab   \n",
       "19180      G   T       376         377              99.7  nsp14 in orf1ab   \n",
       "21304      C   T        37          37               100  nsp16 in orf1ab   \n",
       "23403      A   G       348         352              98.9            spike   \n",
       "24034      C   T       389         396              98.2            spike   \n",
       "25563      G   T       161         162              99.4            orf3A   \n",
       "25907      G   T       189         190              99.5            orf3A   \n",
       "27964      C   T       124         124               100             orf8   \n",
       "28472      C   T       150         154              97.4            geneN   \n",
       "28869      C   T       234         240              97.5            geneN   \n",
       "\n",
       "         Amino acid mutation  \n",
       "Position                      \n",
       "241                           \n",
       "1059                   T265I  \n",
       "1358                   V365I  \n",
       "2437                   R724S  \n",
       "3037                          \n",
       "4633                          \n",
       "8083                  M2606I  \n",
       "10319                 L3352F  \n",
       "12473                         \n",
       "13201                         \n",
       "14408                  P314L  \n",
       "14805                         \n",
       "16748                 K1094R  \n",
       "18424                 N1653D  \n",
       "19180                 V1905L  \n",
       "21304                 R2613C  \n",
       "23403                  D614G  \n",
       "24034                         \n",
       "25563                   Q57H  \n",
       "25907                  G172V  \n",
       "27964                   S24L  \n",
       "28472                   P67S  \n",
       "28869                  P199L  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add in depth info\n",
    "!grep -v \"^#\" variants.vcf > variants.vcf.noheaders\n",
    "\n",
<<<<<<< HEAD
    "# Check if there are no variants detected\n",
    "if os.path.getsize(\"variants.vcf.noheaders\") == 0:\n",
    "    n_snps = 0\n",
    "    n_snps_mindepth = 0\n",
    "else:\n",
    "    variant_table = variant_table.set_index('Position')\n",
    "    df_vcf = pd.read_csv(\"variants.vcf.noheaders\", \\\n",
    "                         sep='\\t', \\\n",
    "                         usecols=[1,7], \\\n",
    "                         names=['position','info'], \\\n",
    "                         index_col=['position']\\\n",
    "                        )\n",
    "    for position in df_vcf.index:\n",
    "        SR = df_vcf.loc[position,'info'].rsplit(';SR=')[1].rsplit(';')[0]\n",
    "        ref_reads = int(SR.rsplit(',')[0]) + int(SR.rsplit(',')[1])\n",
    "        alt_reads = int(SR.rsplit(',')[2]) + int(SR.rsplit(',')[3])\n",
    "        variant_table.loc[position, 'Alt depth'] = \"{:,.0f}\".format(alt_reads)\n",
    "        alt_frequency = alt_reads/(alt_reads + ref_reads)*100\n",
    "        if alt_frequency == 100:\n",
    "            variant_table.loc[position, 'Alt frequency (%)'] = \"{:,.0f}\".format(alt_frequency)\n",
    "        else:\n",
    "            variant_table.loc[position, 'Alt frequency (%)'] = \"{:,.1f}\".format(alt_frequency)\n",
    "        variant_table.loc[position, 'Total depth'] = \"{:,.0f}\".format(ref_reads + alt_reads)\n",
    "\n",
    "    variant_table = variant_table[['Ref','Alt','Alt depth','Total depth','Alt frequency (%)','Gene','Amino acid mutation']]\n",
    "    variant_table = variant_table.fillna('')\n",
    "    display(variant_table)\n",
    "    n_snps = variant_table.shape[0]\n",
    "    n_snps_mindepth = sum(variant_table['Total depth'] > MIN_DEPTH)"
=======
    "variant_table = variant_table.set_index('Position')\n",
    "\n",
    "df_vcf = pd.read_csv(\"variants.vcf.noheaders\", \\\n",
    "                     sep='\\t', \\\n",
    "                     usecols=[1,7], \\\n",
    "                     names=['position','info'], \\\n",
    "                     index_col=['position']\\\n",
    "                    )\n",
    "for position in df_vcf.index:\n",
    "    SR = df_vcf.loc[position,'info'].rsplit(';SR=')[1].rsplit(';')[0]\n",
    "    ref_reads = int(SR.rsplit(',')[0]) + int(SR.rsplit(',')[1])\n",
    "    alt_reads = int(SR.rsplit(',')[2]) + int(SR.rsplit(',')[3])\n",
    "    variant_table.loc[position, 'Alt depth'] = int(alt_reads)\n",
    "    variant_table.loc[position, 'Alt frequency (%)'] = \"{:,.2f}\".format(alt_reads/(alt_reads + ref_reads)*100)\n",
    "    variant_table.loc[position, 'Total depth'] = int(ref_reads + alt_reads)\n",
    "\n",
    "variant_table = variant_table[['Ref','Alt','Alt depth','Total depth','Alt frequency (%)','Gene','Amino acid mutation']]"
>>>>>>> 36501a1319792a87593bb10c5ddfc0d0260378ba
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "n_snps = variant_table.shape[0]\n",
    "n_snps_mindepth = sum(variant_table['Total depth'] > MIN_DEPTH)\n",
    "\n",
>>>>>>> 36501a1319792a87593bb10c5ddfc0d0260378ba
    "nextclade_pm_count = nextclade_json['qc']['privateMutations']['total']\n",
    "nextclade_lineage = nextclade_json['clade']\n",
    "\n",
    "pangolin_lineage = pangolin_table['lineage'].iloc[0]\n",
    "pangolin_version = pangolin_table['pangoLEARN_version'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"SARS-CoV-2 (COVID-19) Sequencing Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-effd9c1cbaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m text = f\"\"\"\n\u001b[1;32m      2\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mreport\u001b[0m \u001b[0msummarizes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0mof\u001b[0m \u001b[0mSARS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mCoV\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m<\u001b[0m\u001b[0mstrong\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0msample_filename\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstrong\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mA\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0mx\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfident\u001b[0m \u001b[0mSNV\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0ma\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://doi.org/10.1038/s41467-020-20075-6\"\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbenchmarking\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mof\u001b[0m \u001b[0mSARS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mCoV\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0mgenome\u001b[0m \u001b[0msequences\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mARTIC\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0mamplicon\u001b[0m \u001b[0mprotocols\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mONT\u001b[0m \u001b[0msequencing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_filename' is not defined"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "This report summarizes the detection of SARS-CoV-2 single-nucleotide variants (SNVs) in sample \n",
    "<strong>{sample_filename}</strong>.\n",
    "\n",
    "<p>A minimum depth of 50x was chosen for confident SNV detection based on <a href=\"https://doi.org/10.1038/s41467-020-20075-6\">benchmarking</a> of SARS-CoV-2 sequencing data generated with ARTIC network amplicon protocols and ONT sequencing. This benchmarking study also concludes that ONT sequencing is unsuitable for detection of small indel varants, which we do no report here.\n",
    "\n",
    "<p>This sample contained <strong>{n_reads:,}</strong> reads, with\n",
    "<strong>{proportion_mapped_reads:.1%}</strong> mapping to the \n",
    "<a href='https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3/' target='_blank'>Wuhan-Hu-1 reference</a>.\n",
    "Reads span <strong>{cov:.0%}</strong> of the genome, with a mean depth of <strong>{mean_depth:.0f}x</strong>, and {cov_mindepth:.0%} of the genome covered at depths >{MIN_DEPTH:}x.</p>\n",
    "\n",
    "<p>A total of <strong>{n_snps_mindepth}</strong> variant{'s were' if n_snps_mindepth != 1 else 'was'} detected at depths >{MIN_DEPTH:}x.\n",
    "This genome is classified as Pangolin lineage <strong>{pangolin_lineage}</strong> using PangoLEARN version {pangolin_version} and Nextclade lineage <strong>{nextclade_lineage}</strong> with {nextclade_pm_count} private mutation{'s' if nextclade_pm_count != 1 else ''}.</p>\"\"\"\n",
    "\n",
    "HTML(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reference_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45abacaa0cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Coverage plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreference_length_kb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m plot = (\n\u001b[1;32m      5\u001b[0m     \u001b[0malt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_depths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reference_length' is not defined"
     ]
    }
   ],
   "source": [
    "# Coverage plot\n",
    "reference_length_kb = reference_length // 1000\n",
    "\n",
    "plot = (\n",
    "    alt.Chart(binned_depths)\n",
    "    .mark_area()\n",
    "    .transform_window(rolling_mean=\"mean(depth)\", frame=[-50, 50])\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"position\",\n",
    "            title=\"Genomic Coordinate (kb)\",\n",
    "            scale=alt.Scale(domain=[0, reference_length_kb]),\n",
    "        ),\n",
    "        y=alt.Y(\"rolling_mean:Q\", scale=alt.Scale(type=\"linear\"), title=\"Depth\"),\n",
    "    )\n",
    "    .properties(\n",
    "        title=f\"SARS-CoV-2 ({REFERENCE_NAME})\",\n",
    "        width=550,\n",
    "        height=150,\n",
    "    )\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./nextclade.json\") as handle:\n",
    "    nextclade_results = json.load(handle)\n",
    "    assert len(nextclade_results) == 1, \"expected exactly 1 item in nextclade.json\"\n",
    "    nextclade = nextclade_results[0]\n",
    "    \n",
    "# # flatten nextclade results\n",
    "# # deletions don't have positions\n",
    "# nc_flat = []\n",
    "# for _type in {'substitutions', 'deletions', 'insertions'}:\n",
    "#     for row in nextclade[_type]:\n",
    "#         aa_key = f'aa{_type.capitalize()}'\n",
    "#         if len(row.get(aa_key, [])) == 0:\n",
    "#             # synonymous mutation\n",
    "#             nc_flat.append({\n",
    "#                 \"n\": 1,\n",
    "#                 \"type\": _type,\n",
    "#                 'ref': row.get('refNuc', '-'),\n",
    "#                 'pos': row.get('pos', row.get('start')),\n",
    "#                 'alt': row.get('queryNuc', '-'),\n",
    "#                 'gene': row.get('gene', '-'),\n",
    "#                 'ref_aa': '-',\n",
    "#                 'query_aa': '-'\n",
    "#             })\n",
    "#         else:\n",
    "#             for n, aa_substitution in enumerate(row[aa_key], start=1):\n",
    "#                 nc_flat.append({\n",
    "#                     \"n\": n,\n",
    "#                     \"type\": _type,\n",
    "#                     'ref': row['refNuc'],\n",
    "#                     'pos': row.get('pos', row.get('start')),\n",
    "#                     'alt': row['queryNuc'],\n",
    "#                     'gene': row.get('gene', '-'),\n",
    "#                     'ref_aa': aa_substitution['queryAA'],\n",
    "#                     'query_aa': aa_substitution['refAA']\n",
    "#                 })\n",
    "                \n",
    "# pd.DataFrame(nc_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "if os.path.getsize(\"variants.vcf.noheaders\") != 0:\n",
    "    HTML(variant_table[variant_table['total_depth'] > MIN_DEPTH].to_html(index=False))\n",
    "    legend_text = \"SARS-CoV-2 variants.\"\n",
    "\n",
    "    n_extra_variants = (\n",
    "        sum(variant_table[\"total_depth\"] > MIN_DEPTH) if not variant_table.empty else 0\n",
    "    )\n",
=======
    "HTML(variant_table[variant_table['Total depth'] > MIN_DEPTH].to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_text = \"SARS-CoV-2 variants.\"\n",
    "\n",
    "n_extra_variants = (\n",
    "    sum(variant_table[\"Total depth\"] > MIN_DEPTH) if not variant_table.empty else 0\n",
    ")\n",
>>>>>>> 36501a1319792a87593bb10c5ddfc0d0260378ba
    "\n",
    "    if n_extra_variants > 0:\n",
    "        legend_text += f\" An additional {n_extra_variants} variant{'s' if n_extra_variants > 1 else ''} <{MIN_DEPTH}Ã— depth {'are' if n_extra_variants > 1 else 'is'} not shown.\"\n",
    "\n",
    "\n",
    "    if os.environ.get(\"ONE_CODEX_REPORT_UUID\"):\n",
    "        legend_text += f\"\"\" \n",
    "             A variants TSV and consensus FASTA is available <a target=\"_blank\" href=\\\"{'https://app.onecodex.com/report/' + os.environ['ONE_CODEX_REPORT_UUID'] + '/files'}\\\">here</a>.\n",
    "            \"\"\"\n",
    "    HTML(\n",
    "        '<div style=\"text-align: center; padding-top: 10px; font-size: 0.7em; color: #777;\"><em>'\n",
    "        + legend_text\n",
    "        + \"</em></div>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- Additional bioinformatics pipeline details are [available on GitHub](https://github.com/onecodex/sars-cov-2)\n",
    "- [Nextstrain](https://nextstrain.org/ncov) maintains an up-to-date analysis of SARS-CoV-2 (HCoV-19).\n",
    "- The [Global Initiative on Sharing All Influenza Data (GISAID)](https://www.gisaid.org/) hosts viral genomes from ongoing outbreaks. Please [contact us](mailto:hello@onecodex.com) for help submitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add One Codex report ID to footer for reproducibility/data provenance (not yet in v0.7.2)\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "<style type='text/css'>\n",
    "@page {{\n",
    "    @bottom-center {{\n",
    "        content: \"{os.environ['ONE_CODEX_REPORT_UUID'] + ' -' if os.environ.get('ONE_CODEX_REPORT_UUID') else ''} NOT FOR DIAGNOSTIC USE\" !important;\n",
    "    }}\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a JSON too, including filtered variants <50x\n",
    "results = {\n",
    "    \"n_reads\": n_reads,\n",
    "    \"n_mapped_reads\": n_mapped_reads,\n",
    "    \"report_id\": os.environ.get(\"ONE_CODEX_REPORT_UUID\"), \n",
    "    \"sample_id\": os.environ.get(\"ONE_CODEX_SAMPLE_UUID\"),\n",
    "    \"variants\": variant_table.to_dict(orient='records'),\n",
    "    \"coverage\": cov,\n",
    "    \"coverage_over_50x\": cov_mindepth,\n",
    "    \"mean_depth\": mean_depth,\n",
    "    \"median_depth\": median_depth,\n",
    "    \"nextclade_results\": nextclade,\n",
    "    \"variant_table\": variant_table.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "with gzip.open(f\"{sample.filename}.report.json.gz\", \"w\") as f:\n",
    "    f.write(json.dumps(results).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up files\n",
    "!rm -f {sample.filename} snps.depth variants.log covid19.bam.bai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
