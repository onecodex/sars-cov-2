{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import altair as alt\n",
    "import math\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from Bio import SeqIO\n",
    "from IPython.display import HTML\n",
    "from onecodex.notebooks.report import set_logo, set_style, title\n",
    "import onecodex\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import dnaplotlib as dpl\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "import warnings # to avoid printing \"FixedFormatter should only be used together with FixedLocator\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # This only works sometimes...\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.rcParams.update({'font.family':'Fira Sans', \"font.size\": 12})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_path = os.environ.get(\"ONE_CODEX_REPORT_LOGO\")\n",
    "\n",
    "if logo_path:\n",
    "    display(set_logo(logo_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the snpEff-generated tsv (variants.vcf with annotations and irrelevant information filtered out)\n",
    "### as the basis for the variants table.\n",
    "### The \"allele_reads_by_strand\" column is either the Medaka-generated SR or bcftools-generated DP4\n",
    "\n",
    "def read_tsv_as_dataframe(path):\n",
    "\n",
    "\n",
    "        df_snpeff = pd.read_csv(path, sep=\"\\t\", dtype={'POS': 'int32', \\\n",
    "                                                           'REF': 'str', \\\n",
    "                                                           'ALT': 'str', \\\n",
    "                                                           'allele reads by strand': 'str', \\\n",
    "                                                           'ANN[0].EFFECT': 'str', \\\n",
    "                                                           'ANN[0].HGVS P': 'str', \\\n",
    "                                                           'BCSQ': 'str'\n",
    "                                                          },)\n",
    "        \n",
    "\n",
    "        if df_snpeff.empty: # If there are no variants\n",
    "            df_snpeff = pd.DataFrame()\n",
    "        else:\n",
    "            df_snpeff = df_snpeff.rename(columns={\"REF\": \"Ref\", \\\n",
    "                                                          \"ALT\": \"Alt\", \\\n",
    "                                                          \"ANN[0].HGVS P\": \"Variant effect\", \\\n",
    "                                                          \"ANN[0].EFFECT\": \"Variant type\", \\\n",
    "                                                          \"BCSQ\": \"Linkage\"\n",
    "                                                         })\n",
    "\n",
    "            if INSTRUMENT_VENDOR == 'Illumina':\n",
    "                position_column = \"Position (first ref nt)\"\n",
    "            elif INSTRUMENT_VENDOR == 'Oxford Nanopore':\n",
    "                position_column = \"Position\"\n",
    "\n",
    "            df_snpeff = df_snpeff.rename(columns={\"POS\": position_column})\n",
    "            df_snpeff[\"Missense mutation\"] = \"\"\n",
    "            df_snpeff = df_snpeff.reset_index()\n",
    "\n",
    "            for i in df_snpeff.index:\n",
    "                depths = [int(x) for x in str(df_snpeff.loc[i,'allele reads by strand']).split(\",\")]\n",
    "                if sum(depths[:]) == 0:\n",
    "                    df_snpeff = df_snpeff.drop(index=i)\n",
    "                else:\n",
    "                    df_snpeff.loc[i,'Alt depth'] = '{:.0f}'.format(sum(depths[2:]))\n",
    "                    df_snpeff.loc[i,'Ref depth'] = '{:.0f}'.format(sum(depths[:2]))\n",
    "                    df_snpeff.loc[i,'Total depth'] = '{:.0f}'.format(sum(depths[:]))\n",
    "                    alt_freq = sum(depths[2:])/sum(depths[:])*100\n",
    "                    if alt_freq == 100:\n",
    "                        df_snpeff.loc[i,'Alt frequency (%)'] = '{:.0f}'.format(alt_freq)\n",
    "                    else:\n",
    "                        df_snpeff.loc[i,'Alt frequency (%)'] = '{:.2f}'.format(alt_freq)\n",
    "\n",
    "            df_snpeff = df_snpeff.set_index(position_column)\n",
    "            \n",
    "        return df_snpeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecodex.Api() # initialize plot embedding\n",
    "pass # don't print anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path(os.environ[\"RESULTS_DIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENT_VENDOR = os.environ[\"INSTRUMENT_VENDOR\"]\n",
    "ARTIC_PRIMER_VERSION = os.environ[\"ARTIC_PRIMER_VERSION\"]\n",
    "\n",
    "if INSTRUMENT_VENDOR == 'Illumina':\n",
    "    MIN_DEPTH = 10\n",
    "elif INSTRUMENT_VENDOR == 'Oxford Nanopore':\n",
    "    MIN_DEPTH= 50\n",
    "else:\n",
    "    raise Exception(f\"Invalid sequencing platform: ${INSTRUMENT_VENDOR}\")\n",
    "\n",
    "SAMPLE_PATH = os.environ.get(\"SAMPLE_PATH\") or glob(os.path.join(RESULTS_DIR, \"*.fastq.gz\"))[0]\n",
    "\n",
    "# outputs of bioinformatics pipeline (default paths)\n",
    "VARIANTS_VCF_PATH = RESULTS_DIR / \"variants.vcf\"\n",
    "VARIANTS_SNPEFF_PATH = RESULTS_DIR / \"variants.snpeff.tsv\"\n",
    "NEXTCLADE_JSON = RESULTS_DIR / \"nextclade.json\"\n",
    "NEXTCLADE_TSV_PATH = RESULTS_DIR / \"nextclade.tsv\"\n",
    "PANGOLIN_CSV_PATH = RESULTS_DIR / \"pangolin.csv\"\n",
    "CONSENSUS_PATH = RESULTS_DIR / \"consensus.fa\"\n",
    "SNPS_DEPTH_PATH = RESULTS_DIR / \"snps.depth\"\n",
    "AA_CODES_PATH = RESULTS_DIR / \"aa_codes.txt\"\n",
    "\n",
    "# databases\n",
    "REFERENCE_PATH = os.environ.get(\"FASTA_REFERENCE\", \"/share/nCoV-2019.reference.fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total reads\n",
    "\n",
    "def is_gz_file(filepath):  \n",
    "    # https://stackoverflow.com/questions/3703276/how-to-tell-if-a-file-is-gzip-compressed\n",
    "    with open(filepath, \"rb\") as test_f:\n",
    "        return test_f.read(2) == b\"\\x1f\\x8b\"\n",
    "\n",
    "total_reads = 0\n",
    "\n",
    "if is_gz_file(SAMPLE_PATH):\n",
    "    with gzip.open(SAMPLE_PATH, \"rt\") as handle:\n",
    "        for line in handle:\n",
    "            total_reads += 1\n",
    "else:\n",
    "    with open(SAMPLE_PATH, \"rt\") as handle:\n",
    "        for line in handle:\n",
    "            total_reads += 1\n",
    "\n",
    "total_reads = total_reads / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference genome\n",
    "reference = list(SeqIO.parse(CONSENSUS_PATH, \"fasta\"))\n",
    "reference_length = len(reference[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate before\n",
    "with open(RESULTS_DIR / \"total_mapped_reads.txt\") as handle:\n",
    "    total_mapped_reads = int(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_table = []\n",
    "\n",
    "with open(SNPS_DEPTH_PATH) as handle:\n",
    "    for line in handle:\n",
    "        row = line.strip().split(\"\\t\")\n",
    "        if len(row) == 1:\n",
    "            continue\n",
    "        depth_table.append(\n",
    "            {\"reference\": row[0], \"position\": int(row[1]), \"depth\": int(row[2])}\n",
    "        )\n",
    "depth_table = pd.DataFrame(depth_table, columns=[\"reference\", \"position\", \"depth\"])\n",
    "\n",
    "if (depth_table.values == 0).any():\n",
    "    warning_messages.append(\"One or more bases are spanned by zero reads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate genome coverage (what percent of bases are coveraged at X coverage)\n",
    "# Use a fixed reference length that we use for `samtools depth` above\n",
    "\n",
    "covered_sites = set()\n",
    "covered_sites_mindepth = set()\n",
    "\n",
    "for _, row in depth_table.iterrows():\n",
    "    row = row.to_dict()\n",
    "    if row[\"depth\"] >= 1:\n",
    "        covered_sites.add(row[\"position\"])\n",
    "    if row[\"depth\"] >= MIN_DEPTH:\n",
    "        covered_sites_mindepth.add(row[\"position\"]) \n",
    "\n",
    "cov = len(covered_sites) / reference_length\n",
    "if cov <= 0.9:\n",
    "    warning_messages.append(\n",
    "        \"The consensus sequence is too incomplete for GISAID submission (reads must span >90% of the reference).\"\n",
    "    )\n",
    "cov_mindepth = len(covered_sites_mindepth) / reference_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_depth = depth_table[\"depth\"].mean() if not depth_table.empty else 0\n",
    "median_depth = depth_table[\"depth\"].median() if not depth_table.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Nextclade and Pangolin tables\n",
    "\n",
    "if not os.path.exists(PANGOLIN_CSV_PATH):\n",
    "    warning_messages.append(\"No pangolin output\")\n",
    "    have_pangolin = False\n",
    "else:\n",
    "    have_pangolin = True\n",
    "    pangolin_table = pd.read_csv(PANGOLIN_CSV_PATH, sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nextclade JSON\n",
    "##### Please note that everything in the Nextclade JSON (nt positions, ranges, codon positions) is 0-indexed,\n",
    "##### but SARS-CoV-2 variants (and most things) are reported as 1-indexed.\n",
    "\n",
    "with open(NEXTCLADE_JSON) as json_file:\n",
    "    nextclade_json = json.load(json_file)\n",
    "    \n",
    "# get nextclade version for pdf\n",
    "nextclade_version = nextclade_json.get(\"nextcladeAlgoVersion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(nextclade_json.get(\"errors\")) > 0:\n",
    "    have_nextclade = False\n",
    "    nextclade_lineage = None    \n",
    "    for errors1 in nextclade_json[\"errors\"]:\n",
    "        for errors2 in errors1[\"errors\"]:\n",
    "            warning_messages.append('(Nextclade Error) '\n",
    "                                    + errors2)      \n",
    "    n_variants_mindepth = None\n",
    "    n_variants = None\n",
    "    nextclade_pm_count = None\n",
    "    variants_table = pd.DataFrame()\n",
    "    \n",
    "elif int(nextclade_json.get('results')[0]['totalSubstitutions']) ==0:\n",
    "    warning_messages.append(\"No variants detected\")\n",
    "    have_nextclade = True\n",
    "    nextclade_lineage = None\n",
    "    n_variants_mindepth = 0\n",
    "    n_variants = 0\n",
    "    nextclade_pm_count = 0\n",
    "    variants_table = pd.DataFrame()\n",
    "\n",
    "else:\n",
    "    have_nextclade = True\n",
    "    # Add in gene info\n",
    "    df_orfs = pd.read_csv(\n",
    "        RESULTS_DIR / \"annot_table.orfs.txt\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[\"gene\", \"start\", \"stop\"],\n",
    "        dtype={\"gene\": \"str\", \"start\": \"int32\", \"stop\": \"int32\"}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "################## If ONT, do not report indels and use Nextclade as the source of SNV information\n",
    "    if INSTRUMENT_VENDOR == 'Oxford Nanopore':\n",
    "\n",
    "        # load nextclade JSON\n",
    "        rows_list = [] #for subst in nextclade_json[\"substitutions\"]:  # Each substitution is a dictionary\n",
    "        for subst in nextclade_json.get('results')[0]['substitutions']:  # update to reflect new json format\n",
    "            dict1 = {}\n",
    "            dict1[\"Position\"] = (\n",
    "                subst[\"pos\"] + 1 # update to reflect new json format\n",
    "            )  # JSON positions are 0-indexed; convert to 1-index\n",
    "            dict1[\"Ref\"] = subst[\"refNuc\"]\n",
    "            dict1[\"Alt\"] = subst[\"queryNuc\"]\n",
    "            if len(subst[\"aaSubstitutions\"]) != 0:\n",
    "                for mutation in subst[\n",
    "                    \"aaSubstitutions\"\n",
    "                ]:  # JSON codons are 0-indexed; convert to 1-index\n",
    "                    dict1[\"Missense mutation\"] = (\n",
    "                        mutation[\"refAA\"] + str(mutation[\"codon\"] + 1) + mutation[\"queryAA\"]\n",
    "                    )\n",
    "            else:\n",
    "                dict1[\"Missense mutation\"] = \"\"\n",
    "            rows_list.append(dict1)\n",
    "\n",
    "        df_nextclade = pd.DataFrame(rows_list)\n",
    "        # in case mutations are outside of genes\n",
    "        df_nextclade['Gene'] = ''\n",
    "\n",
    "        # Add in low-complexity region info\n",
    "        df_low_complexity = pd.read_csv(RESULTS_DIR / \"low_complexity_regions.txt\", sep=\"\\t\", header=None, usecols=[1,2], names=[\"start\",\"stop\"])\n",
    "\n",
    "        # join nextclade, VCF data and ORF annotations\n",
    "\n",
    "        for i in df_nextclade.index:\n",
    "\n",
    "            for j in df_orfs.index:\n",
    "                if (\n",
    "                    df_orfs.loc[j, \"start\"]\n",
    "                    <= df_nextclade.loc[i, \"Position\"]\n",
    "                    <= df_orfs.loc[j, \"stop\"]\n",
    "                ):\n",
    "                    df_nextclade.loc[i, \"Gene\"] = df_orfs.loc[j, \"gene\"]\n",
    "\n",
    "        # Add in a flag for a low-complexity region              \n",
    "            for k in df_low_complexity.index:\n",
    "                if (\n",
    "                    df_low_complexity.loc[k, \"start\"]\n",
    "                    <= df_nextclade.loc[i, \"Position\"]\n",
    "                    <= df_low_complexity.loc[k, \"stop\"]\n",
    "                ):\n",
    "                    df_nextclade.loc[i, \"Low complexity region\"] = \"X\"\n",
    "                else:\n",
    "                    df_nextclade.loc[i, \"Low complexity region\"] = \"\"\n",
    "\n",
    "        variant_table = df_nextclade.set_index(\"Position\")\n",
    "\n",
    "\n",
    "        # load variants VCF\n",
    "        df_vcf = read_tsv_as_dataframe(VARIANTS_SNPEFF_PATH)\n",
    "        \n",
    "        # Check that the same variant is always called from both amplicons spanning a position\n",
    "        df_vcf = df_vcf.reset_index()\n",
    "        df_dup = df_vcf[df_vcf[\"Position\"].duplicated(keep=False)]\n",
    "        for i in np.unique(df_dup[\"Position\"]):\n",
    "            alt_list = df_dup[df_dup[\"Position\"]==i][\"Alt\"].tolist()\n",
    "            assert alt_list[0] == alt_list[1],\"Different variants are called between pools 1 and 2 for at least one position.\"\n",
    "\n",
    "        # Instead of summing depths (will give much higher reads for positions with duplicate calls),\n",
    "        # just keep the first call (this is the one that is annotated with BCSQ).\n",
    "        \n",
    "        for dup_position in np.unique(df_dup[\"Position\"].tolist()):\n",
    "            drop_index = max(df_dup[df_dup[\"Position\"]==dup_position].index.tolist())\n",
    "            df_vcf = df_vcf.drop(index=drop_index)\n",
    "        df_vcf = df_vcf.set_index(\"Position\")\n",
    "        df_vcf = df_vcf[[\"Variant type\",\"Variant effect\",\"Alt depth\",\"Ref depth\",\"Total depth\",\"Alt frequency (%)\"]]\n",
    "\n",
    "\n",
    "        variants_table = variant_table.merge(\n",
    "            df_vcf, left_index=True, right_index=True, how=\"left\"\n",
    "        )\n",
    "\n",
    "        \n",
    "        display_columns = [\n",
    "            \"Ref\",\n",
    "            \"Alt\",\n",
    "            \"Alt depth\",\n",
    "            \"Total depth\",\n",
    "            \"Alt frequency (%)\",\n",
    "            \"Gene\",\n",
    "            \"Variant type\",\n",
    "            \"Missense mutation\",\n",
    "            \"Low complexity region\"\n",
    "        ]\n",
    "\n",
    "       \n",
    "        \n",
    "        variants_table = variants_table[display_columns]\n",
    "        \n",
    "############ End ONT\n",
    "\n",
    "############ If Illumina, indels are valid. Just use SnpEff annotations for the variants table\n",
    "\n",
    "    elif INSTRUMENT_VENDOR == \"Illumina\":\n",
    "            \n",
    "        df_aa_codes = pd.read_csv(AA_CODES_PATH, sep='\\t', index_col=\"Three-Letter Code\")\n",
    "        \n",
    "        df_snpeff = read_tsv_as_dataframe(VARIANTS_SNPEFF_PATH)\n",
    "        \n",
    "        # One position can have multiple variants, so don't use position as index\n",
    "        df_snpeff = df_snpeff.reset_index()\n",
    "\n",
    "        # In case no SNVs are located in genes\n",
    "        df_snpeff[\"Gene\"] = \"\"\n",
    "        for i in df_snpeff.index:\n",
    "                \n",
    "            #### Add in gene information\n",
    "            for j in df_orfs.index:\n",
    "                if (\n",
    "                    df_orfs.loc[j, \"start\"]\n",
    "                    <= i\n",
    "                    <= df_orfs.loc[j, \"stop\"]\n",
    "                ):\n",
    "                    df_snpeff.loc[i, \"Gene\"] = df_orfs.loc[j, \"gene\"]\n",
    "\n",
    "\n",
    "            ### Fill in all missense variants with missense mutation (convert HGVS notation to one-letter code)\n",
    "            if 'missense variant' in df_snpeff.loc[i,'Variant type']:\n",
    "                aa_mut = df_snpeff.loc[i,'Variant effect'].rsplit('.')[1]\n",
    "                if aa_mut[-3:] in df_aa_codes.index:\n",
    "                    queryAA = df_aa_codes.loc[aa_mut[-3:], \"One-Letter Code\"]\n",
    "                    refAA = df_aa_codes.loc[aa_mut[0:3], \"One-Letter Code\"]\n",
    "                    codon = \"\"\n",
    "                    for z in aa_mut:\n",
    "                        if z.isdigit():\n",
    "                            codon = codon + z\n",
    "                    df_snpeff.loc[i, \"Missense mutation\"] = refAA + codon + queryAA\n",
    "            else:\n",
    "                df_snpeff.loc[i, \"Missense mutation\"] = ''\n",
    "                \n",
    "            ### Identify subsitutions linked to another variant on the same codon;\n",
    "            ### replace their missense mutation with the linked one\n",
    "            if '@' in str(df_snpeff.loc[i,\"Linkage\"]): # If the variant is linked to another variant\n",
    "                position_linked = int(df_snpeff.loc[i,\"Linkage\"].rsplit('@')[1].rsplit(',')[0])\n",
    "                type_linked = df_snpeff[df_snpeff['Position (first ref nt)']==position_linked][\"Variant type\"] # the effect of the linked variant\n",
    "                # If linkage points to another substitution on the same codon\n",
    "                if any(word in type_linked for word in [\"synonymous\",\"missense\"]):\n",
    "                    df_snpeff.loc[i,\"Missense mutation\"] = df_snpeff.loc[position_linked,\"Missense mutation\"]                \n",
    "\n",
    "        df_snpeff = df_snpeff.drop(columns={\"allele reads by strand\"})\n",
    "        df_snpeff = df_snpeff.fillna(\"\")\n",
    "        df_snpeff = df_snpeff[[\"Position (first ref nt)\", \"Ref\", \"Alt\", \"Alt depth\", \"Total depth\", \"Alt frequency (%)\", \\\n",
    "                                  \"Gene\", \"Variant type\", \"Missense mutation\"]]\n",
    "        df_snpeff = df_snpeff.set_index(\"Position (first ref nt)\")\n",
    "        variants_table = df_snpeff\n",
    "        \n",
    "    \n",
    "    n_variants = variants_table.shape[0]\n",
    "    n_variants_mindepth = sum(variants_table[\"Total depth\"].astype(float) > MIN_DEPTH)\n",
    "    \n",
    "    nextclade_lineage = nextclade_json.get('results')[0]['customNodeAttributes']['clade_nextstrain']\n",
    "    nextclade_pm_count = nextclade_json.get('results')[0]['privateNucMutations']['totalPrivateSubstitutions']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if have_pangolin:\n",
    "\n",
    "    pangolin_lineage = pangolin_table['lineage'][0]\n",
    "    pangolin_version = pangolin_table['pangolin_version'][0]\n",
    "    \n",
    "    \n",
    "    # Do not assign a Pangolin or Nextclade lineage if consensus does not pass QC\n",
    "    \n",
    "    for record in SeqIO.parse(CONSENSUS_PATH, \"fasta\"):\n",
    "    \n",
    "        if record.seq.count(\"N\") > 20000:\n",
    "            pangolin_lineage=\"unassigned\"\n",
    "            nextclade_lineage=\"unassigned\"\n",
    "            warning_messages.append(\n",
    "                \"The consensus sequence has too many ambiguous bases: \"\n",
    "                + str('{:,}'.format(record.seq.count(\"N\")))\n",
    "                + f\" N's against the \"\n",
    "                + str('{:,}'.format(reference_length))\n",
    "                + \" base reference sequence.\"\n",
    "            )\n",
    "        # Split contig into unambiguous stretches\n",
    "        runs = re.split(\n",
    "            r\"[^ATGC]\", str(record.seq)\n",
    "        )  \n",
    "        max_len = len(max(runs, key=len))  # Length of longest unambiguous stretch\n",
    "\n",
    "        if max_len < 10000:\n",
    "            pangolin_lineage=\"Cannot be confidently assigned\"\n",
    "            nextclade_lineage=\"Cannot be confidently assigned\"\n",
    "            warning_messages.append(\n",
    "                \"The consensus sequence is too incomplete for GISAID submission: the longest stretch of unambiguous bases is only \"\n",
    "                + str('{:,}'.format(max_len))\n",
    "                + \" bases (must be over 10,000).\"\n",
    "            )\n",
    "        \n",
    "else:\n",
    "    warning_messages.append(\"Pangolin failed\")\n",
    "    pangolin_lineage = \"Undetected or error\"\n",
    "    pangolin_version = \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"SARS-CoV-2 (COVID-19) Sequencing Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "if INSTRUMENT_VENDOR == \"Oxford Nanopore\":\n",
    "    variant_description = \"single-nucleotide variants (SNVs)\"\n",
    "elif INSTRUMENT_VENDOR == \"Illumina\":\n",
    "    variant_description = \"variants\"\n",
    "    \n",
    "text.append(f\"\"\"\n",
    "<p>\n",
    "This report summarizes the detection of SARS-CoV-2 {variant_description} in sample \n",
    "<strong>{os.path.basename(SAMPLE_PATH)}</strong>, generated on the <strong>{INSTRUMENT_VENDOR}</strong> sequencing platform with ARTIC V{ARTIC_PRIMER_VERSION} primers.\n",
    "</p>\n",
    "\"\"\") \n",
    "    \n",
    "text.append(f\"\"\"\n",
    "<p>This sample contained <strong>{int(total_reads):,}</strong> read{'' if total_reads == 1 else 's'}, with\n",
    "<strong>{total_mapped_reads / total_reads:.1%}</strong> mapping to the \n",
    "<a href='https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3/' target='_blank'>Wuhan-Hu-1 reference</a>.\n",
    "Reads span <strong>{cov:.0%}</strong> of the genome, with a mean depth of <strong>{mean_depth:.0f}x</strong>, a median depth of <strong>{median_depth:.0f}x</strong>, and {cov_mindepth:.0%} of the genome covered at depth >{MIN_DEPTH:}x.\n",
    "</p>\n",
    "\"\"\")\n",
    "\n",
    "if total_mapped_reads >= 1:\n",
    "    \n",
    "    if INSTRUMENT_VENDOR == \"Oxford Nanopore\":\n",
    "        text.append(f\"\"\"\n",
    "        <p>A total of <strong>{n_variants_mindepth}</strong> SNV{'s were' if n_variants_mindepth != 1 else ' was'} detected \n",
    "    at depths >{MIN_DEPTH:}x, the minimum depth chosen for confident SNV detection based on \n",
    "        <a href=\"https://doi.org/10.1038/s41467-020-20075-6\">benchmarking</a> of Oxford Nanopore sequencing data. \n",
    "        Vertical black lines on the coverage plot below show the depth of high quality reads (may be less than total reads) for each SNV. </p>\n",
    "\n",
    "        <p>SNV detection in low complexity regions (ex: homopolymer-rich) is less accurate and flagged in the table below.\n",
    "        Oxford Nanopore sequencing is unsuitable for detection of small indel varants, which we do not report here.\n",
    "        </p>\n",
    "        \"\"\")\n",
    "        \n",
    "    elif INSTRUMENT_VENDOR == \"Illumina\":\n",
    "        text.append(f\"\"\"\n",
    "        <p>A total of <strong>{n_variants_mindepth}</strong> variant{'s were' if n_variants_mindepth != 1 else ' was'} detected \n",
    "    at depths >{MIN_DEPTH:}x, the minimum depth chosen for confident variant detection using Illumina sequencing data. \n",
    "    Vertical black lines on the coverage plot below show the depth of high quality reads (may be less than total reads) for each variant.</p>\n",
    "        \"\"\")\n",
    "\n",
    "    if pangolin_lineage == \"Cannot be confidently assigned\":\n",
    "        text.append(f\"\"\"<p>The genome quality is too low to confidently assign a Pangolin or Nextclade lineage (see warning messages).</p>\"\"\")\n",
    "    else:\n",
    "        text.append(f\"\"\"\n",
    "    <p>This genome is classified as Pangolin lineage <strong>{pangolin_lineage}</strong> using Pangolin\n",
    "    version {pangolin_version} and Nextclade lineage <strong>{nextclade_lineage}</strong> using Nextclade version {nextclade_version} with <strong>{nextclade_pm_count} \n",
    "    private mutation{'s' if nextclade_pm_count != 1 else ''}</strong> detected.\n",
    "    </p>\n",
    "    \"\"\")\n",
    "\n",
    "HTML(\"\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "\n",
    "# Un-smoothed coverage plot in matplotlib\n",
    "\n",
    "#######################\n",
    "\n",
    "if total_mapped_reads >= 1: # Do not plot at all if there are no reads\n",
    "    ############### Define genome diagram design \n",
    "\n",
    "    cur_region = [0, 30000]\n",
    "\n",
    "    # Colors\n",
    "    col_map = {}\n",
    "    col_map['grey'] = \"#6e6e6e\"\n",
    "    col_map['ocx_signature_green'] = \"#128887\"\n",
    "    col_map['ocx_navy_blue'] = \"#16347B\"\n",
    "    col_map['ocx_blue'] = \"#0072C7\"\n",
    "    col_map['ocx_light_blue'] = \"#01ACEC\"\n",
    "    col_map['ocx_cyan'] =\"#97E9FC\"\n",
    "    col_map['ocx_forest_green'] = \"#0A605E\"\n",
    "    col_map['ocx_kelly_green'] = \"#1DA893\"\n",
    "    col_map['ocx_blue_green'] = \"#3DD8BE\"\n",
    "    col_map['ocx_pastel_green'] = \"#ABEFE2\"\n",
    "    col_map['ocx_dark_purple'] = \"#37257D\"\n",
    "    col_map['ocx_purple'] = \"#9C78E0\"\n",
    "    col_map['ocx_pastel_purple'] = \"#CBC0F9\"\n",
    "    col_map['ocx_light_purple'] = \"#E3DDFF\"\n",
    "    col_map['ocx_burnt_sienna'] = \"#BC5B00\"\n",
    "    col_map['ocx_orange'] = \"#EB984A\"\n",
    "    col_map['ocx_yellow'] = \"#FCE34D\"\n",
    "    col_map['ocx_light_yellow'] = \"#FEF2A3\"\n",
    "    col_map['ocx_dark_red'] = \"#950303\"\n",
    "    col_map['ocx_red'] = \"#DD3A3A\"\n",
    "    col_map['ocx_coral'] = \"#FF8D8B\"\n",
    "    col_map['ocx_peach'] = \"#FFD5CB\"\n",
    "    col_map['ocx_dark_magenta'] = \"#771354\"\n",
    "    col_map['ocx_magenta'] = \"#C13A8B\"\n",
    "    col_map['ocx_pink'] = \"#F28BBF\"\n",
    "    col_map['ocx_light_pink'] = \"#F9D9E7\"\n",
    "\n",
    "    # dnaplotlib formatting options\n",
    "\n",
    "    # Some additional parameters that can be set:\n",
    "    # 'label_style':'italic'\n",
    "    # 'linewidth':1.0\n",
    "    # 'arrowhead_length':8,\n",
    "\n",
    "    Y_OFFSET=8\n",
    "    LABEL_ROTATION=45\n",
    "    LABEL_SIZE=9.5 # font size\n",
    "    LINEWIDTH=0.1\n",
    "    LINECOLOR=\"#3b3b3b\"\n",
    "    SNP_LINEWIDTH=0.85\n",
    "    EDGE_COLOR=col_map['grey']\n",
    "\n",
    "    opt_orf1ab = { 'label':'orf1ab', 'label_color':col_map['ocx_blue'], 'label_y_offset':Y_OFFSET, \\\n",
    "                  'color':col_map['ocx_blue'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                 'linewidth':LINEWIDTH, 'linecolor':LINECOLOR, 'edgecolor':EDGE_COLOR }\n",
    "    opt_spike = { 'label':'spike', 'label_color':col_map['ocx_red'], 'label_y_offset':Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_red'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'linecolor':LINECOLOR, 'edgecolor':EDGE_COLOR }\n",
    "    opt_orf3a = {'label':'orf3a', 'label_color':col_map['ocx_orange'], 'label_y_offset':-Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_orange'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'label_x_offset':-500, 'edgecolor':EDGE_COLOR }\n",
    "    opt_geneE = {'label':'geneE', 'label_color':\"#a296d6\", 'label_y_offset':Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_pastel_purple'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'label_x_offset':500, 'edgecolor':EDGE_COLOR }\n",
    "    opt_geneM = {'label':'geneM', 'label_color':col_map['ocx_light_blue'], 'label_y_offset':-Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_light_blue'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'label_x_offset':-500, 'edgecolor':EDGE_COLOR }\n",
    "    opt_orf6 = {'label':'orf6', 'label_color':\"#a9db7d\", 'label_y_offset':Y_OFFSET, \\\n",
    "                'color':\"#cdffa1\", 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "               'linewidth':LINEWIDTH, 'label_x_offset':400, 'edgecolor':EDGE_COLOR }\n",
    "    opt_orf7a = {'label':'orf7a', 'label_color':col_map['ocx_coral'], 'label_y_offset':-Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_coral'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'label_x_offset':-400, 'edgecolor':EDGE_COLOR }\n",
    "    opt_orf8 = {'label':'orf8', 'label_color':col_map['ocx_magenta'], 'label_y_offset':Y_OFFSET, \\\n",
    "                'color':col_map['ocx_magenta'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "               'linewidth':LINEWIDTH, 'label_x_offset':500, 'edgecolor':EDGE_COLOR }\n",
    "    opt_geneN = {'label':'geneN', 'label_color':'#90decf', 'label_y_offset':-Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_pastel_green'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'label_x_offset':-500, 'edgecolor':EDGE_COLOR }\n",
    "    opt_orf10 = {'label':'orf10', 'label_color':\"#e6bcce\", 'label_y_offset':Y_OFFSET, \\\n",
    "                 'color':col_map['ocx_light_pink'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "                'linewidth':LINEWIDTH, 'label_x_offset':500, 'edgecolor':EDGE_COLOR }\n",
    "    opt_snv = { 'color':'black' , 'linewidth':SNP_LINEWIDTH }\n",
    "\n",
    "    # Define ORFs (if want arrows instead of blocks, switch to 'type':'CDS')\n",
    "    ORF1AB = {'type':'UserDefined', 'name':'orf1ab', 'start':266,  'end':21555, 'fwd':True, 'opts':opt_orf1ab}\n",
    "    SPIKE = {'type':'UserDefined', 'name':'spike', 'start':21563, 'end':25384, 'fwd':True, 'opts':opt_spike}\n",
    "    ORF3A = {'type':'UserDefined', 'name':'orf3a', 'start':25393, 'end':26220, 'fwd':True, 'opts':opt_orf3a}\n",
    "    GENEE = {'type':'UserDefined', 'name':'geneE', 'start':26245, 'end':26472, 'fwd':True, 'opts':opt_geneE}\n",
    "    GENEM = {'type':'UserDefined', 'name':'geneM', 'start':26523, 'end':27191, 'fwd':True, 'opts':opt_geneM}\n",
    "    ORF6 = {'type':'UserDefined', 'name':'orf6', 'start':27202, 'end':27387, 'fwd':True, 'opts':opt_orf6}\n",
    "    ORF7A = {'type':'UserDefined', 'name':'orf6', 'start':27394, 'end':27759, 'fwd':True, 'opts':opt_orf7a}\n",
    "    ORF8 = {'type':'UserDefined', 'name':'orf8', 'start':27894, 'end':28259, 'fwd':True, 'opts':opt_orf8}\n",
    "    GENEN = {'type':'UserDefined', 'name':'geneN', 'start':28274, 'end':29533, 'fwd':True, 'opts':opt_geneN}\n",
    "    ORF10 = {'type':'UserDefined', 'name':'orf10', 'start':29558, 'end':29674, 'fwd':True, 'opts':opt_orf10}\n",
    "\n",
    "    # A design is merely a list of parts and their properties\n",
    "    design = [ORF1AB, SPIKE, ORF3A, GENEE, GENEM, ORF6, ORF7A, ORF8, GENEN, ORF10]\n",
    "\n",
    "    # Add SNVs to the design\n",
    "    if not variants_table.empty:\n",
    "        for position, row in variants_table.iterrows():\n",
    "            START=position\n",
    "            END=position+1\n",
    "            design.append({'type':'UserDefined', 'name':'snv', 'start':START,  'end':END, 'fwd':True, 'opts':opt_snv})\n",
    "\n",
    "\n",
    "    ################# Plot genome diagram\n",
    "\n",
    "    # Create the overall figure\n",
    "    fig = plt.figure(figsize=(8,2), dpi=300)\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[0.4, 1])\n",
    "\n",
    "    # Create the DNAplotlib renderer\n",
    "    dr = dpl.DNARenderer(scale=15, linewidth=0.9)\n",
    "\n",
    "    # Render the orfs to axis\n",
    "    ax_dna = plt.subplot(gs[0])\n",
    "    start, end = dr.renderDNA(ax_dna, design, dr.trace_part_renderers(), plot_backbone=True)\n",
    "    ax_dna.set_xlim(cur_region)\n",
    "    ax_dna.set_ylim([-5,8])\n",
    "    ax_dna.axis('off')\n",
    "\n",
    "\n",
    "    ################# Plot coverage\n",
    "\n",
    "    # Generate axes for coverage plot\n",
    "    ax = plt.subplot(gs[1])\n",
    "\n",
    "\n",
    "    ###### x-axis\n",
    "\n",
    "    ax.set_xlim(cur_region)\n",
    "    ax.set_xlabel('Genomic Coordinate (kb)', fontsize=12, labelpad=5)\n",
    "\n",
    "    # Set x-axis ticks to kb\n",
    "    labels = ax.get_xticks().tolist()\n",
    "    labels_kb = [int(float(label)/1000) for label in labels]\n",
    "    ax.set_xticklabels(labels_kb)\n",
    "\n",
    "    # Set 5 minor ticks per major tick\n",
    "    from matplotlib.ticker import AutoMinorLocator\n",
    "    minor_locator = AutoMinorLocator(5)\n",
    "    ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "    ###### y-axis\n",
    "\n",
    "    ax.set_ylabel('Depth', fontsize=12, labelpad=5)\n",
    "\n",
    "    # Set y-axis limits according to maximum depth in sample\n",
    "    ax.set_yscale('log')\n",
    "    if depth_table['depth'].max() > 0:\n",
    "        exp = math.ceil(math.log10(depth_table['depth'].max()))\n",
    "    else:\n",
    "        exp = 0\n",
    "    yaxis_max = 10**exp\n",
    "    ax.set_ylim((1,yaxis_max))\n",
    "\n",
    "    # y-axis major ticks at every multiple of 10\n",
    "    locmaj = mticker.LogLocator(base=10, numticks=20) # numticks should be > number of ticks to display\n",
    "    ax.yaxis.set_major_locator(locmaj)\n",
    "\n",
    "    # y-axis major tick labels: commas at thousands\n",
    "    ax.get_yaxis().set_major_formatter(mticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "    # y-axis minor ticks (5 per major tick)\n",
    "    locmin = mticker.LogLocator(base=10.0,subs=(0.2,0.4,0.6,0.8),numticks=20)\n",
    "    ax.yaxis.set_minor_locator(locmin)\n",
    "    ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "\n",
    "\n",
    "    ##### axis colors and spine visiblity\n",
    "\n",
    "    # Set axis colors to grey; show only the bottom and left spines\n",
    "    for SPINE in ['bottom', 'left']:\n",
    "        ax.spines[SPINE].set_color(col_map['grey'])\n",
    "    for SPINE in ['right', 'top']:\n",
    "        ax.spines[SPINE].set_visible(False)\n",
    "    for AXIS in ['x', 'y']:\n",
    "        ax.tick_params(axis=AXIS, which='both', colors=col_map['grey'], labelsize=10)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "\n",
    "    ##### Plot depths as a colored fill\n",
    "    plt.fill_between(depth_table['position'], depth_table['depth'], color=col_map['ocx_kelly_green'])\n",
    "\n",
    "    ##### Show min depth as grey dashed line\n",
    "    plt.hlines(y=MIN_DEPTH, xmin=0, xmax=30000, linestyle='--', linewidth=0.5, color=col_map['grey'])\n",
    "\n",
    "    ##### Show SNVs and color according to AA mutation\n",
    "    if not variants_table.empty:\n",
    "        for position, row in variants_table[variants_table[\"Total depth\"].astype(float) > MIN_DEPTH].iterrows():\n",
    "            yvalue = depth_table.loc[depth_table['position'] == position, 'depth'].iloc[0]\n",
    "            xvalue = np.arange(position-0.45, position+0.45)\n",
    "            plt.fill_between(xvalue, yvalue, color=\"black\", linewidth=SNP_LINEWIDTH)\n",
    "\n",
    "\n",
    "    ############# Update subplot spacing\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.45, left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "\n",
    "    ############# Close and save\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    fig.savefig(\"covplot.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "    import base64\n",
    "    with open(\"covplot.png\", \"rb\") as handle:\n",
    "        data = handle.read()\n",
    "    plot_data = base64.b64encode(data).decode('utf-8')\n",
    "\n",
    "    display(HTML(f'<img src=\"data:image/png;base64, {plot_data}\"/>'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200000)\n",
    "\n",
    "if not variants_table.empty: # If there are variants   \n",
    "    # Display full tables up to 200 rows\n",
    "\n",
    "    variants_table_display = variants_table.rename(columns={\"Alt depth\": \"Alt depth (high quality reads)\", \\\n",
    "                                                      \"Total depth\": \"Total depth (high quality reads)\" \\\n",
    "                                                     })\n",
    "    variants_table_display_filtered = variants_table_display[variants_table_display['Total depth (high quality reads)'].astype(float) > MIN_DEPTH]\n",
    "    \n",
    "    if variants_table_display_filtered.empty:\n",
    "        display(HTML(f\"No variants detected.\"))\n",
    "    else:\n",
    "        display(variants_table_display_filtered)\n",
    "        legend_text = \"SARS-CoV-2 variants.\"\n",
    "\n",
    "        n_extra_variants = (\n",
    "            n_variants - n_variants_mindepth if not variants_table.empty else 0\n",
    "        )\n",
    "\n",
    "        if n_extra_variants > 0:\n",
    "            legend_text += f\" An additional {n_extra_variants} variant{'s' if n_extra_variants > 1 else ''} <{MIN_DEPTH}× depth {'are' if n_extra_variants > 1 else 'is'} not shown.\"\n",
    "\n",
    "        if os.environ.get(\"ONE_CODEX_REPORT_UUID\"):\n",
    "            legend_text += f\"\"\" \n",
    "                 A variants TSV and consensus FASTA is available <a target=\"_blank\" href=\\\"{'https://app.onecodex.com/report/' + os.environ['ONE_CODEX_REPORT_UUID'] + '/files'}\\\">here</a>.\n",
    "                \"\"\"\n",
    "        try:\n",
    "            git_commit_no = subprocess.check_output(['git', 'log','-n','1','--pretty=format:\"%H\"'], stderr=subprocess.STDOUT).decode('utf-8')\n",
    "            commit_text = f\" This report was generated with commit number {git_commit_no}.\"\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            commit_text = \"Could not retrieve git commit hash. rc=\" + str(e.returncode) + \"; output=\" + str(e.output)\n",
    "\n",
    "        display(HTML(\n",
    "            '<div style=\"text-align: center; padding-top: 10px; font-size: 0.7em; color: #777;\"><em>'\n",
    "            + legend_text\n",
    "            + '<p style=\"text-align:center\">'\n",
    "            + commit_text\n",
    "            + \"</p></em></div>\"\n",
    "        ))\n",
    "    \n",
    "else:\n",
    "    display(HTML(f\"No variants detected.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- Additional bioinformatics pipeline details are [available on GitHub](https://github.com/onecodex/sars-cov-2)\n",
    "- [Nextstrain](https://nextstrain.org/ncov) maintains an up-to-date analysis of SARS-CoV-2 (HCoV-19).\n",
    "- The [Global Initiative on Sharing All Influenza Data (GISAID)](https://www.gisaid.org/) hosts viral genomes from ongoing outbreaks. Please [contact us](mailto:hello@onecodex.com) for help submitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add One Codex report ID to footer for reproducibility/data provenance (not yet in v0.7.2)\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "<style type='text/css'>\n",
    "@page {{\n",
    "    @bottom-center {{\n",
    "        content: \"{os.environ['ONE_CODEX_REPORT_UUID'] + ' -' if os.environ.get('ONE_CODEX_REPORT_UUID') else ''} NOT FOR DIAGNOSTIC USE\" !important;\n",
    "    }}\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a JSON too, including filtered variants <50x\n",
    "results = {\n",
    "    \"n_reads\": total_reads,\n",
    "    \"n_mapped_reads\": total_mapped_reads,\n",
    "    \"report_id\": os.environ.get(\"ONE_CODEX_REPORT_UUID\"), \n",
    "    \"sample_id\": os.environ.get(\"ONE_CODEX_SAMPLE_UUID\"),\n",
    "    \"variants\": variants_table.to_dict(orient='records') if n_variants else None,\n",
    "    \"coverage\": cov,\n",
    "    \"coverage_over_min_depth\": cov_mindepth,\n",
    "    \"min_depth\": MIN_DEPTH,\n",
    "    \"mean_depth\": mean_depth,\n",
    "    \"median_depth\": median_depth,\n",
    "    \"nextclade_results\": nextclade_json,\n",
    "    \"nextclade_lineage\": nextclade_lineage,\n",
    "    \"pangolin_results\": pangolin_table.to_dict(orient='records'),\n",
    "    \"pangolin_lineage\": pangolin_lineage,\n",
    "    \"warnings\": warning_messages,\n",
    "}\n",
    "\n",
    "with gzip.open(f\"{os.path.basename(SAMPLE_PATH)}.report.json.gz\", \"w\") as f:\n",
    "    f.write(json.dumps(results).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(warning_messages) > 0:\n",
    "    display(HTML(\"<ul>\"))\n",
    "    display(HTML(\"<h1>Warning Messages</h1>\"))    \n",
    "    for message in set(warning_messages):\n",
    "        display(HTML(f\"<li>{message}</li>\"))\n",
    "    display(HTML(\"</ul>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
