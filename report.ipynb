{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import altair as alt\n",
    "import math\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from Bio import SeqIO\n",
    "from IPython.display import HTML\n",
    "from onecodex.notebooks.report import set_style, title\n",
    "import onecodex\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import dnaplotlib as dpl\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf_as_dataframe(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=\"\\t\",\n",
    "        comment=\"#\",\n",
    "        names=[\"CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\"],\n",
    "        usecols=[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    )\n",
    "\n",
    "    # parse info add key/value items to data-frame\n",
    "    info_data = []\n",
    "    for row in df[\"INFO\"].values:\n",
    "        items = [i.split(\"=\") for i in row.split(\";\")]\n",
    "        parsed = {}\n",
    "        for item in items:\n",
    "            # boolean items. skip for now\n",
    "            if len(item) == 1:\n",
    "                pass\n",
    "            elif len(item) == 2:\n",
    "                parsed[item[0]] = item[1]\n",
    "            else:\n",
    "                raise Exception(f\"Item of unexpected length in vcf info column: {item}\")\n",
    "\n",
    "        if \"DP4\" in parsed.keys():\n",
    "            depth_column = \"DP4\"\n",
    "        elif \"SR\" in parsed.keys():\n",
    "            depth_column = \"SR\"\n",
    "        else:\n",
    "            raise Exception(\"Cannot determine 4x depth column\")\n",
    "\n",
    "        # parse depth column into ALT and REF depths\n",
    "        depths = [int(x) for x in parsed[depth_column].split(\",\")]\n",
    "        parsed[\"ALT_DP\"] = sum(depths[2:])\n",
    "        parsed[\"REF_DP\"] = sum(depths[:2])\n",
    "        info_data.append(parsed)\n",
    "\n",
    "    df = pd.DataFrame([{**r, **i} for r, i in zip(df.to_dict(orient=\"records\"), info_data)])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecodex.Api() # initialize plot embedding\n",
    "pass # don't print anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path(os.environ.get(\"RESULTS_DIR\", os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENT_VENDOR = os.getenv(\"INSTRUMENT_VENDOR\", \"Illumina\")\n",
    "\n",
    "if INSTRUMENT_VENDOR == 'Illumina':\n",
    "    MIN_DEPTH = 10\n",
    "elif INSTRUMENT_VENDOR == 'Oxford Nanopore':\n",
    "    MIN_DEPTH= 50\n",
    "else:\n",
    "    raise Exception(f\"Invalid sequencing platform: ${INSTRUMENT_VENDOR}\")\n",
    "\n",
    "SAMPLE_PATH = os.environ.get(\"SAMPLE_PATH\") or glob(os.path.join(RESULTS_DIR, \"*.fastq.gz\"))[0]\n",
    "\n",
    "# outputs of bioinformatics pipeline (default paths)\n",
    "VARIANTS_VCF_PATH = RESULTS_DIR / \"variants.vcf\"\n",
    "NEXTCLADE_JSON = RESULTS_DIR / \"nextclade.json\"\n",
    "NEXTCLADE_TSV_PATH = RESULTS_DIR / \"nextclade.tsv\"\n",
    "PANGOLIN_CSV_PATH = RESULTS_DIR / \"pangolin.csv\"\n",
    "CONSENSUS_PATH = RESULTS_DIR / \"consensus.fa\"\n",
    "SNPS_DEPTH_PATH = RESULTS_DIR / \"snps.depth\"\n",
    "\n",
    "\n",
    "# databases\n",
    "REFERENCE_PATH = os.environ.get(\"FASTA_REFERENCE\", \"/share/nCoV-2019.reference.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes this is slow but it doesn't require an API call\n",
    "# (but it would be nice to not need the fastq as this point maybe. maybe this is in the bam file?)\n",
    "total_reads = 0\n",
    "with gzip.open(SAMPLE_PATH, \"rt\") as handle:\n",
    "    for line in handle:\n",
    "        total_reads += 1\n",
    "total_reads = total_reads / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference genome\n",
    "reference = list(SeqIO.parse(CONSENSUS_PATH, \"fasta\"))\n",
    "reference_length = len(reference[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate before\n",
    "with open(RESULTS_DIR / \"total_mapped_reads.txt\") as handle:\n",
    "    total_mapped_reads = int(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_table = []\n",
    "\n",
    "with open(SNPS_DEPTH_PATH) as handle:\n",
    "    for line in handle:\n",
    "        row = line.strip().split(\"\\t\")\n",
    "        if len(row) == 1:\n",
    "            continue\n",
    "        depth_table.append(\n",
    "            {\"reference\": row[0], \"position\": int(row[1]), \"depth\": int(row[2])}\n",
    "        )\n",
    "depth_table = pd.DataFrame(depth_table, columns=[\"reference\", \"position\", \"depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate genome coverage (what percent of bases are coveraged at X coverage)\n",
    "# Use a fixed reference length that we use for `samtools depth` above\n",
    "\n",
    "covered_sites = set()\n",
    "covered_sites_mindepth = set()\n",
    "\n",
    "for _, row in depth_table.iterrows():\n",
    "    row = row.to_dict()\n",
    "    if row[\"depth\"] >= 1:\n",
    "        covered_sites.add(row[\"position\"])\n",
    "    if row[\"depth\"] >= MIN_DEPTH:\n",
    "        covered_sites_mindepth.add(row[\"position\"])\n",
    "\n",
    "cov = len(covered_sites) / reference_length\n",
    "if cov <= 0.9:\n",
    "    warning_messages.append(\n",
    "        \"The consensus sequence is too incomplete for GISAID submission (reads must span >90% of the reference).\"\n",
    "    )\n",
    "cov_mindepth = len(covered_sites_mindepth) / reference_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean over windows because altair can't handle > 5k points ...\n",
    "binned_depths = []\n",
    "window_width = reference_length // 4500\n",
    "\n",
    "for i in range(1, reference_length, window_width):\n",
    "    window = depth_table.loc[\n",
    "        (depth_table[\"position\"] > i) & (depth_table[\"position\"] < i + window_width)\n",
    "    ]\n",
    "\n",
    "    binned_depths.append(\n",
    "        {\"position\": i, \"depth\": window[\"depth\"].mean(),}\n",
    "    )\n",
    "\n",
    "binned_depths = pd.DataFrame(binned_depths)\n",
    "# Convert position from bp to kbp, to improve how the coverage plot looks\n",
    "binned_depths[\"position\"] = binned_depths[\"position\"]/1000\n",
    "mean_depth = depth_table[\"depth\"].mean() if not depth_table.empty else 0\n",
    "median_depth = depth_table[\"depth\"].median() if not depth_table.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Nextclade and Pangolin tables\n",
    "\n",
    "if not os.path.exists(PANGOLIN_CSV_PATH):\n",
    "    warning_messages.append(\"No pangolin output\")\n",
    "    have_pangolin = False\n",
    "else:\n",
    "    have_pangolin = True\n",
    "    pangolin_table = pd.read_csv(PANGOLIN_CSV_PATH, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nextclade JSON\n",
    "##### Please note that everything in the Nextclade JSON (nt positions, ranges, codon positions) is 0-indexed,\n",
    "##### but SARS-CoV-2 variants (and most things) are reported as 1-indexed.\n",
    "\n",
    "with open(NEXTCLADE_JSON) as json_file:\n",
    "    nextclade_json = json.load(json_file)\n",
    "    assert len(nextclade_json) == 1, f\"expected exactly 1 result in: {nextclade_json}\"\n",
    "    nextclade_json = nextclade_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(nextclade_json[\"errors\"]) > 0:\n",
    "    have_nextclade = False\n",
    "    nextclade_lineage = None\n",
    "    warning_messages.extend(nextclade_json[\"errors\"])\n",
    "    n_snps_mindepth = None\n",
    "    n_snps = None\n",
    "    nextclade_pm_count = None\n",
    "    variants_table = pd.DataFrame()\n",
    "elif len(nextclade_json['substitutions']) == 0:\n",
    "    warning_messages.append(\"No variants detected\")\n",
    "    have_nextclade = True\n",
    "    nextclade_lineage = None\n",
    "    n_snps_mindepth = 0\n",
    "    n_snps = 0\n",
    "    nextclade_pm_count = 0\n",
    "    variants_table = pd.DataFrame()    \n",
    "else:\n",
    "    have_nextclade = True\n",
    "\n",
    "    # Generate warnings if indels are detected? (ONT does not reliably detect these)\n",
    "    if INSTRUMENT_VENDOR == \"Oxford Nanopore\":\n",
    "        if nextclade_json[\"insertions\"] != [] or nextclade_json[\"deletions\"] != []:\n",
    "            warning_messages.append(\"Indels were detected (ONT cannot reliably detect these).\")\n",
    "\n",
    "    # load nextclade JSON\n",
    "    rows_list = []\n",
    "    for subst in nextclade_json[\"substitutions\"]:  # Each substitution is a dictionary\n",
    "        dict1 = {}\n",
    "        dict1[\"Position\"] = (\n",
    "            subst[\"pos\"] + 1\n",
    "        )  # JSON positions are 0-indexed; convert to 1-index\n",
    "        dict1[\"Ref\"] = subst[\"refNuc\"]\n",
    "        dict1[\"Alt\"] = subst[\"queryNuc\"]\n",
    "        if len(subst[\"aaSubstitutions\"]) != 0:\n",
    "            for mutation in subst[\n",
    "                \"aaSubstitutions\"\n",
    "            ]:  # JSON codons are 0-indexed; convert to 1-index\n",
    "                dict1[\"Amino acid mutation\"] = (\n",
    "                    mutation[\"refAA\"] + str(mutation[\"codon\"] + 1) + mutation[\"queryAA\"]\n",
    "                )\n",
    "        else:\n",
    "            dict1[\"Amino acid mutation\"] = \"\"\n",
    "        rows_list.append(dict1)\n",
    "\n",
    "    df_nextclade = pd.DataFrame(rows_list)\n",
    "    # in case mutations are outside of Genes\n",
    "    df_nextclade['Gene'] = '-'\n",
    "    \n",
    "    # load variants VCF\n",
    "    df_vcf = read_vcf_as_dataframe(VARIANTS_VCF_PATH)\n",
    "    \n",
    "    # Add in gene info\n",
    "    df_orfs = pd.read_csv(\n",
    "        \"./annot_table.orfs.txt\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[\"gene\", \"start\", \"stop\"],\n",
    "    )\n",
    "    \n",
    "    # Add in low-complexity region info\n",
    "    df_low_complexity = pd.read_csv(RESULTS_DIR / \"low_complexity_regions.txt\", sep=\"\\t\", header=None, usecols=[1,2], names=[\"start\",\"stop\"])\n",
    "    \n",
    "    # join nextclade, VCF data and ORF annotations\n",
    "    # Add in a flag if variant is in a low-complexity region\n",
    "    \n",
    "    for i in df_nextclade.index:\n",
    "        for j in df_orfs.index:\n",
    "            if (\n",
    "                df_orfs.loc[j, \"start\"]\n",
    "                <= df_nextclade.loc[i, \"Position\"]\n",
    "                <= df_orfs.loc[j, \"stop\"]\n",
    "            ):\n",
    "                df_nextclade.loc[i, \"Gene\"] = df_orfs.loc[j, \"gene\"]\n",
    "        for k in df_low_complexity.index:\n",
    "            if (\n",
    "                df_low_complexity.loc[k, \"start\"]\n",
    "                <= df_nextclade.loc[i, \"Position\"]\n",
    "                <= df_low_complexity.loc[k, \"stop\"]\n",
    "            ):\n",
    "                df_nextclade.loc[i, \"Low complexity region\"] = \"X\"\n",
    "            else:\n",
    "                df_nextclade.loc[i, \"Low complexity region\"] = \"\"\n",
    "\n",
    "    # df_nextclade in depth info\n",
    "    variant_table = df_nextclade.set_index(\"Position\")\n",
    "\n",
    "    df_vcf[\"TOT_DP\"] = df_vcf[\"REF_DP\"] + df_vcf[\"ALT_DP\"]\n",
    "    \n",
    "    # Check that the same variant is always called from both amplicons spanning a position\n",
    "    df_vcf = df_vcf.reset_index()\n",
    "    df_dup = df_vcf[df_vcf[\"POS\"].duplicated(keep=False)]\n",
    "    for i in np.unique(df_dup[\"POS\"]):\n",
    "        alt_list = df_dup[df_dup[\"POS\"]==i][\"ALT\"].tolist()\n",
    "#        display(i,alt_list)\n",
    "#        assert {all(element == alt_list[0] for element in alt_list)} == {True}\n",
    "\n",
    "        \n",
    "    # sum depths between multiple pools\n",
    "    summed = (\n",
    "        df_vcf[[\"POS\", \"REF_DP\", \"ALT_DP\", \"TOT_DP\"]]\n",
    "        .groupby(\"POS\")\n",
    "        .agg(sum)\n",
    "    )\n",
    "\n",
    "    summed[\"Alt frequency (%)\"] = (\n",
    "        summed[\"ALT_DP\"] / (summed[\"ALT_DP\"] + summed[\"REF_DP\"]) * 100\n",
    "    )\n",
    "\n",
    "    pd.options.display.float_format = \"{:,.2f}\".format\n",
    "    variants_table = variant_table.merge(\n",
    "        summed, left_index=True, right_index=True, how=\"left\"\n",
    "    )\n",
    "    \n",
    "    display_columns = [\n",
    "        \"Ref\",\n",
    "        \"Alt\",\n",
    "        \"Alt depth\",\n",
    "        \"Total depth\",\n",
    "        \"Alt frequency (%)\",\n",
    "        \"Gene\",\n",
    "        \"Amino acid mutation\",\n",
    "    ]\n",
    "    \n",
    "    if INSTRUMENT_VENDOR == \"Oxford Nanopore\":\n",
    "        display_columns.append(\"Low complexity region\")\n",
    "\n",
    "    variants_table = variants_table.rename(\n",
    "        columns={\n",
    "            \"REF\": \"Ref\",\n",
    "            \"ALT\": \"Alt\",\n",
    "            \"ALT_DP\": \"Alt depth\",\n",
    "            \"TOT_DP\": \"Total depth\",\n",
    "        }\n",
    "    )[display_columns]\n",
    "\n",
    "    n_snps = variants_table.shape[0]\n",
    "    n_snps_mindepth = sum(variants_table[\"Total depth\"] > MIN_DEPTH)\n",
    "\n",
    "    nextclade_pm_count = nextclade_json[\"qc\"][\"privateMutations\"][\"total\"]\n",
    "    nextclade_lineage = nextclade_json[\"clade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if have_pangolin:\n",
    "    pangolin_lineage = pangolin_table[\"lineage\"].iloc[0]\n",
    "    pangolin_version = pangolin_table[\"pangoLEARN_version\"].iloc[0]\n",
    "    \n",
    "    # Do not assign a Pangolin or Nextclade lineage if consensus does not pass QC\n",
    "    \n",
    "    for record in SeqIO.parse(CONSENSUS_PATH, \"fasta\"):\n",
    "    \n",
    "        if record.seq.count(\"N\") > 20000:\n",
    "            pangolin_lineage=\"unassigned\"\n",
    "            nextclade_lineage=\"unassigned\"\n",
    "            warning_messages.append(\n",
    "                \"The consensus sequence has too many ambiguous bases: \"\n",
    "                + str(record.seq.count(\"N\"))\n",
    "                + f\" N's against the {reference_length} base reference sequence.\"\n",
    "            )\n",
    "        # Split contig into unambiguous stretches\n",
    "        runs = re.split(\n",
    "            r\"[^ATGC]\", str(record.seq)\n",
    "        )  \n",
    "        max_len = len(max(runs, key=len))  # Length of longest unambiguous stretch\n",
    "\n",
    "        if max_len < 10000:\n",
    "            pangolin_lineage=\"Cannot be confidently assigned\"\n",
    "            nextclade_lineage=\"Cannot be confidently assigned\"\n",
    "            warning_messages.append(\n",
    "                \"The consensus sequence is too incomplete for GISAID submission: the longest stretch of unambiguous bases is only \"\n",
    "                + str(max_len)\n",
    "                + \" bases (must be over 10,000).\"\n",
    "            )\n",
    "        \n",
    "else:\n",
    "    warning_messages.append(\"Pangolin failed\")\n",
    "    pangolin_lineage = \"Undetected or error\"\n",
    "    pangolin_version = \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"SARS-CoV-2 (COVID-19) Sequencing Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "text.append(f\"\"\"\n",
    "<p>\n",
    "This report summarizes the detection of SARS-CoV-2 single-nucleotide variants (SNVs) in sample \n",
    "<strong>{os.path.basename(SAMPLE_PATH)}</strong> generated on the <strong>{INSTRUMENT_VENDOR}</strong> sequencing platform.\n",
    "</p>\n",
    "\"\"\")\n",
    "    \n",
    "    \n",
    "text.append(f\"\"\"\n",
    "<p>This sample contained <strong>{int(total_reads):,}</strong> reads, with\n",
    "<strong>{total_mapped_reads / total_reads:.1%}</strong> mapping to the \n",
    "<a href='https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3/' target='_blank'>Wuhan-Hu-1 reference</a>.\n",
    "Reads span <strong>{cov:.0%}</strong> of the genome, with a mean depth of <strong>{mean_depth:.0f}x</strong>, and {cov_mindepth:.0%} of the genome covered at depths >{MIN_DEPTH:}x.\n",
    "</p>\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "if INSTRUMENT_VENDOR == \"Oxford Nanopore\":\n",
    "    text.append(f\"\"\"\n",
    "    <p>A total of <strong>{n_snps_mindepth}</strong> SNV{'s were' if n_snps_mindepth != 1 else ' was'} detected \n",
    "at depths >{MIN_DEPTH:}x. A minimum depth of {MIN_DEPTH}x was chosen for confident SNV detection based on \n",
    "    <a href=\"https://doi.org/10.1038/s41467-020-20075-6\">benchmarking</a> of SARS-CoV-2 sequencing data.\n",
    "    \n",
    "    SNV detection in low complexity regions (ex: homopolymer-rich) is less accurate and flagged in the table below.\n",
    "    This benchmarking study also concludes that Oxford Nanopore sequencing is unsuitable for detection of small indel varants,\n",
    "    which we do not report here.\n",
    "    </p>\n",
    "    \"\"\")\n",
    "elif INSTRUMENT_VENDOR == \"Illumina\":\n",
    "    text.append(f\"\"\"\n",
    "    <p>A total of <strong>{n_snps_mindepth}</strong> SNV{'s were' if n_snps_mindepth != 1 else 'was'} detected \n",
    "at depths >{MIN_DEPTH:}x, the minimum depth chosen for confident SNV detection using Illumina sequencing data.</p>\n",
    "    \"\"\")\n",
    "\n",
    "if pangolin_lineage == \"Cannot be confidently assigned\":\n",
    "    text.append(f\"\"\"<p>The genome quality is too low to confidently assign a Pangolin or Nextclade lineage (see warning messages).</p>\"\"\")\n",
    "else:\n",
    "    text.append(f\"\"\"\n",
    "<p>This genome is classified as Pangolin lineage <strong>{pangolin_lineage}</strong> using PangoLEARN\n",
    "version {pangolin_version} and Nextclade lineage <strong>{nextclade_lineage}</strong> with {nextclade_pm_count} \n",
    "private mutation{'s' if nextclade_pm_count != 1 else ''}.\n",
    "</p>\n",
    "\"\"\")\n",
    "\n",
    "HTML(\"\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altair coverage plot with smoothing\n",
    "# reference_length_kb = reference_length // 1000\n",
    "\n",
    "# plot = (\n",
    "#     alt.Chart(binned_depths)\n",
    "#     .mark_area()\n",
    "#     .transform_window(rolling_mean=\"mean(depth)\", frame=[-50, 50])\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             \"position\",\n",
    "#             title=\"Genomic Coordinate (kb)\",\n",
    "#             scale=alt.Scale(domain=[0, reference_length_kb]),\n",
    "#         ),\n",
    "#         y=alt.Y(\"rolling_mean:Q\", scale=alt.Scale(type=\"linear\"), title=\"Depth\"),\n",
    "#     )\n",
    "#     .properties(\n",
    "#         title=f\"SARS-CoV-2\",\n",
    "#         width=550,\n",
    "#         height=150,\n",
    "#     )\n",
    "# )\n",
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "\n",
    "# Un-smoothed coverage plot in matplotlib\n",
    "\n",
    "#######################\n",
    "\n",
    "import warnings # to avoid printing \"FixedFormatter should only be used together with FixedLocator\"\n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#    import md5, sha\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # This only works sometimes...\n",
    "warnings.simplefilter('ignore')\n",
    "    \n",
    "plt.rcParams.update({'font.family':'Fira Sans, Helvetica', \"font.size\": 12})\n",
    "    \n",
    "############### Define genome diagram design \n",
    "\n",
    "cur_region = [0, 30000]\n",
    "\n",
    "# Colors\n",
    "col_map = {}\n",
    "col_map['grey'] = \"#6e6e6e\"\n",
    "col_map['ocx_signature_green'] = \"#128887\"\n",
    "col_map['ocx_navy_blue'] = \"#16347B\"\n",
    "col_map['ocx_blue'] = \"#0072C7\"\n",
    "col_map['ocx_light_blue'] = \"#01ACEC\"\n",
    "col_map['ocx_cyan'] =\"#97E9FC\"\n",
    "col_map['ocx_forest_green'] = \"#0A605E\"\n",
    "col_map['ocx_kelly_green'] = \"#1DA893\"\n",
    "col_map['ocx_blue_green'] = \"#3DD8BE\"\n",
    "col_map['ocx_pastel_green'] = \"#ABEFE2\"\n",
    "col_map['ocx_dark_purple'] = \"#37257D\"\n",
    "col_map['ocx_purple'] = \"#9C78E0\"\n",
    "col_map['ocx_pastel_purple'] = \"#CBC0F9\"\n",
    "col_map['ocx_light_purple'] = \"#E3DDFF\"\n",
    "col_map['ocx_burnt_sienna'] = \"#BC5B00\"\n",
    "col_map['ocx_orange'] = \"#EB984A\"\n",
    "col_map['ocx_yellow'] = \"#FCE34D\"\n",
    "col_map['ocx_light_yellow'] = \"#FEF2A3\"\n",
    "col_map['ocx_dark_red'] = \"#950303\"\n",
    "col_map['ocx_red'] = \"#DD3A3A\"\n",
    "col_map['ocx_coral'] = \"#FF8D8B\"\n",
    "col_map['ocx_peach'] = \"#FFD5CB\"\n",
    "col_map['ocx_dark_magenta'] = \"#771354\"\n",
    "col_map['ocx_magenta'] = \"#C13A8B\"\n",
    "col_map['ocx_pink'] = \"#F28BBF\"\n",
    "col_map['ocx_light_pink'] = \"#F9D9E7\"\n",
    "\n",
    "# dnaplotlib formatting options\n",
    "\n",
    "# Some additional parameters that can be set:\n",
    "# 'label_style':'italic'\n",
    "# 'linewidth':1.0\n",
    "# 'arrowhead_length':8,\n",
    "\n",
    "Y_OFFSET=8\n",
    "LABEL_ROTATION=45\n",
    "LABEL_SIZE=9.5 # font size\n",
    "LINEWIDTH=0.1\n",
    "LINECOLOR=\"#3b3b3b\"\n",
    "SNP_LINEWIDTH=0.85\n",
    "EDGE_COLOR=col_map['ocx_red']\n",
    "\n",
    "opt_orf1ab = { 'label':'orf1ab', 'label_color':col_map['ocx_blue'], 'label_y_offset':Y_OFFSET, \\\n",
    "              'color':col_map['ocx_blue'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "             'linewidth':LINEWIDTH, 'linecolor':LINECOLOR, 'edgecolor':EDGE_COLOR }\n",
    "opt_spike = { 'label':'spike', 'label_color':col_map['ocx_red'], 'label_y_offset':Y_OFFSET, \\\n",
    "             'color':col_map['ocx_red'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'linecolor':LINECOLOR, 'edgecolor':EDGE_COLOR }\n",
    "opt_orf3a = {'label':'orf3a', 'label_color':col_map['ocx_orange'], 'label_y_offset':-Y_OFFSET, \\\n",
    "             'color':col_map['ocx_orange'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'label_x_offset':-500, 'edgecolor':EDGE_COLOR }\n",
    "opt_geneE = {'label':'geneE', 'label_color':\"#a296d6\", 'label_y_offset':Y_OFFSET, \\\n",
    "             'color':col_map['ocx_pastel_purple'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'label_x_offset':500, 'edgecolor':EDGE_COLOR }\n",
    "opt_geneM = {'label':'geneM', 'label_color':col_map['ocx_light_blue'], 'label_y_offset':-Y_OFFSET, \\\n",
    "             'color':col_map['ocx_light_blue'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'label_x_offset':-500, 'edgecolor':EDGE_COLOR }\n",
    "opt_orf6 = {'label':'orf6', 'label_color':\"#a9db7d\", 'label_y_offset':Y_OFFSET, \\\n",
    "            'color':\"#cdffa1\", 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "           'linewidth':LINEWIDTH, 'label_x_offset':400, 'edgecolor':EDGE_COLOR }\n",
    "opt_orf7a = {'label':'orf7a', 'label_color':col_map['ocx_coral'], 'label_y_offset':-Y_OFFSET, \\\n",
    "             'color':col_map['ocx_coral'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'label_x_offset':-400, 'edgecolor':EDGE_COLOR }\n",
    "opt_orf8 = {'label':'orf8', 'label_color':col_map['ocx_magenta'], 'label_y_offset':Y_OFFSET, \\\n",
    "            'color':col_map['ocx_magenta'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "           'linewidth':LINEWIDTH, 'label_x_offset':500, 'edgecolor':EDGE_COLOR }\n",
    "opt_geneN = {'label':'geneN', 'label_color':'#90decf', 'label_y_offset':-Y_OFFSET, \\\n",
    "             'color':col_map['ocx_pastel_green'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'label_x_offset':-500, 'edgecolor':EDGE_COLOR }\n",
    "opt_orf10 = {'label':'orf10', 'label_color':\"#e6bcce\", 'label_y_offset':Y_OFFSET, \\\n",
    "             'color':col_map['ocx_light_pink'], 'label_rotation':LABEL_ROTATION, 'label_size':LABEL_SIZE, \\\n",
    "            'linewidth':LINEWIDTH, 'label_x_offset':500, 'edgecolor':EDGE_COLOR }\n",
    "opt_snv = { 'color':'black' , 'linewidth':SNP_LINEWIDTH }\n",
    "\n",
    "# Define ORFs (if want arrows instead of blocks, switch to 'type':'CDS')\n",
    "ORF1AB = {'type':'UserDefined', 'name':'orf1ab', 'start':266,  'end':21555, 'fwd':True, 'opts':opt_orf1ab}\n",
    "SPIKE = {'type':'UserDefined', 'name':'spike', 'start':21563, 'end':25384, 'fwd':True, 'opts':opt_spike}\n",
    "ORF3A = {'type':'UserDefined', 'name':'orf3a', 'start':25393, 'end':26220, 'fwd':True, 'opts':opt_orf3a}\n",
    "GENEE = {'type':'UserDefined', 'name':'geneE', 'start':26245, 'end':26472, 'fwd':True, 'opts':opt_geneE}\n",
    "GENEM = {'type':'UserDefined', 'name':'geneM', 'start':26523, 'end':27191, 'fwd':True, 'opts':opt_geneM}\n",
    "ORF6 = {'type':'UserDefined', 'name':'orf6', 'start':27202, 'end':27387, 'fwd':True, 'opts':opt_orf6}\n",
    "ORF7A = {'type':'UserDefined', 'name':'orf6', 'start':27394, 'end':27759, 'fwd':True, 'opts':opt_orf7a}\n",
    "ORF8 = {'type':'UserDefined', 'name':'orf8', 'start':27894, 'end':28259, 'fwd':True, 'opts':opt_orf8}\n",
    "GENEN = {'type':'UserDefined', 'name':'geneN', 'start':28274, 'end':29533, 'fwd':True, 'opts':opt_geneN}\n",
    "ORF10 = {'type':'UserDefined', 'name':'orf10', 'start':29558, 'end':29674, 'fwd':True, 'opts':opt_orf10}\n",
    "\n",
    "# A design is merely a list of parts and their properties\n",
    "design = [ORF1AB, SPIKE, ORF3A, GENEE, GENEM, ORF6, ORF7A, ORF8, GENEN, ORF10]\n",
    "\n",
    "# Add SNVs to the design\n",
    "for position, row in variants_table.iterrows():\n",
    "    START=position\n",
    "    END=position+1\n",
    "    design.append({'type':'UserDefined', 'name':'snv', 'start':START,  'end':END, 'fwd':True, 'opts':opt_snv})\n",
    "\n",
    "\n",
    "################# Plot genome diagram\n",
    "\n",
    "# Create the overall figure\n",
    "fig = plt.figure(figsize=(8,2), dpi=300)\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[0.4, 1])\n",
    "\n",
    "# Create the DNAplotlib renderer\n",
    "dr = dpl.DNARenderer(scale=15, linewidth=0.9)\n",
    "\n",
    "# Render the orfs to axis\n",
    "ax_dna = plt.subplot(gs[0])\n",
    "start, end = dr.renderDNA(ax_dna, design, dr.trace_part_renderers(), plot_backbone=True)\n",
    "ax_dna.set_xlim(cur_region)\n",
    "ax_dna.set_ylim([-5,8])\n",
    "ax_dna.axis('off')\n",
    "\n",
    "\n",
    "################# Plot coverage\n",
    "\n",
    "# Generate axes for coverage plot\n",
    "ax = plt.subplot(gs[1])\n",
    "\n",
    "\n",
    "###### x-axis\n",
    "\n",
    "ax.set_xlim(cur_region)\n",
    "ax.set_xlabel('Genomic Coordinate (kb)', fontsize=12, labelpad=5)\n",
    "\n",
    "# Set x-axis ticks to kb\n",
    "labels = ax.get_xticks().tolist()\n",
    "labels_kb = [int(float(label)/1000) for label in labels]\n",
    "ax.set_xticklabels(labels_kb)\n",
    "\n",
    "# Set 5 minor ticks per major tick\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "minor_locator = AutoMinorLocator(6)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "###### y-axis\n",
    "\n",
    "ax.set_ylabel('Depth', fontsize=12, labelpad=5)\n",
    "\n",
    "# Set y-axis limits according to maximum depth in sample\n",
    "ax.set_yscale('log')\n",
    "exp = math.ceil(math.log10(depth_table['depth'].max()))\n",
    "yaxis_max = 10**exp\n",
    "ax.set_ylim((1,yaxis_max))\n",
    "\n",
    "# y-axis major ticks at every multiple of 10\n",
    "locmaj = mticker.LogLocator(base=10, numticks=20) # numticks should be > number of ticks to display\n",
    "ax.yaxis.set_major_locator(locmaj)\n",
    "\n",
    "# y-axis major tick labels: commas at thousands\n",
    "ax.get_yaxis().set_major_formatter(mticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# y-axis minor ticks (5 per major tick)\n",
    "locmin = mticker.LogLocator(base=10.0,subs=(0.2,0.4,0.6,0.8),numticks=20)\n",
    "ax.yaxis.set_minor_locator(locmin)\n",
    "ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "\n",
    "\n",
    "##### axis colors and spine visiblity\n",
    "\n",
    "# Set axis colors to grey; show only the bottom and left spines\n",
    "for SPINE in ['bottom', 'left']:\n",
    "    ax.spines[SPINE].set_color(col_map['grey'])\n",
    "for SPINE in ['right', 'top']:\n",
    "    ax.spines[SPINE].set_visible(False)\n",
    "for AXIS in ['x', 'y']:\n",
    "    ax.tick_params(axis=AXIS, which='both', colors=col_map['grey'], labelsize=10)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "#ax.yaxis.label.set_color(col_map['grey'])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "#ax.xaxis.label.set_color(col_map['grey'])\n",
    "\n",
    "\n",
    "##### Plot depths as a colored fill\n",
    "plt.fill_between(depth_table['position'], depth_table['depth'], color=col_map['ocx_kelly_green'])\n",
    "\n",
    "# If we really want to see single nt positions with low coverage,\n",
    "# we should plot the depths as white over a colored fill\n",
    "#plt.plot(depth_table['position'], depth_table['depth'], color=col_map['ocx_kelly_green'], linestyle='solid', linewidth=0.1)\n",
    "#plt.fill_between(depth_table['position'], depth_table['depth']-10, color=col_map['ocx_kelly_green'])\n",
    "\n",
    "##### Show min depth as grey dashed line\n",
    "plt.hlines(y=MIN_DEPTH, xmin=0, xmax=30000, linestyle='--', linewidth=0.5, color=col_map['grey'])\n",
    "\n",
    "##### Show SNVs and color according to AA mutation\n",
    "for position, row in variants_table.iterrows():\n",
    "    yvalue = depth_table.loc[depth_table['position'] == position, 'depth'].iloc[0]\n",
    "    xvalue = np.arange(position-0.45, position+0.45)\n",
    "    plt.fill_between(xvalue, yvalue, color=\"black\", linewidth=SNP_LINEWIDTH)\n",
    "    \n",
    "    \n",
    "############# Update subplot spacing\n",
    "\n",
    "plt.subplots_adjust(hspace=0.45, left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "\n",
    "############# Close and save\n",
    "\n",
    "plt.close()\n",
    "#plt.show()\n",
    "\n",
    "fig.savefig(\"covplot.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "import base64\n",
    "with open(\"covplot.png\", \"rb\") as handle:\n",
    "    data = handle.read()\n",
    "plot_data = base64.b64encode(data).decode('utf-8')\n",
    "\n",
    "HTML(f'<img src=\"data:image/png;base64, {plot_data}\"/>')\n",
    "\n",
    "#Image(\"covplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_snps_mindepth is None:\n",
    "    display(HTML(\"Nextclade Error. See Warnings below.\"))\n",
    "elif n_snps_mindepth > 0: # If there are variants\n",
    "    display(variants_table[variants_table['Total depth'] > MIN_DEPTH])\n",
    "    legend_text = \"SARS-CoV-2 variants.\"\n",
    "\n",
    "    n_extra_variants = (\n",
    "        sum(variants_table[\"Total depth\"] > MIN_DEPTH) if not variant_table.empty else 0\n",
    "    )\n",
    "\n",
    "    if n_extra_variants > 0:\n",
    "        legend_text += f\" An additional {n_extra_variants} variant{'s' if n_extra_variants > 1 else ''} <{MIN_DEPTH}× depth {'are' if n_extra_variants > 1 else 'is'} not shown.\"\n",
    "\n",
    "\n",
    "    if os.environ.get(\"ONE_CODEX_REPORT_UUID\"):\n",
    "        legend_text += f\"\"\" \n",
    "             A variants TSV and consensus FASTA is available <a target=\"_blank\" href=\\\"{'https://app.onecodex.com/report/' + os.environ['ONE_CODEX_REPORT_UUID'] + '/files'}\\\">here</a>.\n",
    "            \"\"\"\n",
    "    display(HTML(\n",
    "        '<div style=\"text-align: center; padding-top: 10px; font-size: 0.7em; color: #777;\"><em>'\n",
    "        + legend_text\n",
    "        + \"</em></div>\"\n",
    "    ))\n",
    "else:\n",
    "    HTML(f\"No variants detected > {MIN_DEPTH}-x depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- Additional bioinformatics pipeline details are [available on GitHub](https://github.com/onecodex/sars-cov-2)\n",
    "- [Nextstrain](https://nextstrain.org/ncov) maintains an up-to-date analysis of SARS-CoV-2 (HCoV-19).\n",
    "- The [Global Initiative on Sharing All Influenza Data (GISAID)](https://www.gisaid.org/) hosts viral genomes from ongoing outbreaks. Please [contact us](mailto:hello@onecodex.com) for help submitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add One Codex report ID to footer for reproducibility/data provenance (not yet in v0.7.2)\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "<style type='text/css'>\n",
    "@page {{\n",
    "    @bottom-center {{\n",
    "        content: \"{os.environ['ONE_CODEX_REPORT_UUID'] + ' -' if os.environ.get('ONE_CODEX_REPORT_UUID') else ''} NOT FOR DIAGNOSTIC USE\" !important;\n",
    "    }}\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a JSON too, including filtered variants <50x\n",
    "results = {\n",
    "    \"n_reads\": total_reads,\n",
    "    \"n_mapped_reads\": total_mapped_reads,\n",
    "    \"report_id\": os.environ.get(\"ONE_CODEX_REPORT_UUID\"), \n",
    "    \"sample_id\": os.environ.get(\"ONE_CODEX_SAMPLE_UUID\"),\n",
    "    \"variants\": variants_table.to_dict(orient='records') if n_snps else None,\n",
    "    \"coverage\": cov,\n",
    "    \"coverage_over_min_depth\": cov_mindepth,\n",
    "    \"min_depth\": MIN_DEPTH,\n",
    "    \"mean_depth\": mean_depth,\n",
    "    \"median_depth\": median_depth,\n",
    "    \"nextclade_results\": nextclade_json,\n",
    "    \"nextclade_lineage\": nextclade_lineage,\n",
    "    \"pangolin_results\": pangolin_table.to_dict(orient='records'),\n",
    "    \"pangolin_lineage\": pangolin_lineage,\n",
    "    \"warnings\": warning_messages,\n",
    "}\n",
    "\n",
    "with gzip.open(f\"{os.path.basename(SAMPLE_PATH)}.report.json.gz\", \"w\") as f:\n",
    "    f.write(json.dumps(results).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(warning_messages) > 0:\n",
    "    display(HTML(\"<ul>\"))\n",
    "    display(HTML(\"<h1>Warning Messages</h1>\"))    \n",
    "    for message in set(warning_messages):\n",
    "        display(HTML(f\"<li>{message}</li>\"))\n",
    "    display(HTML(\"</ul>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
