{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from Bio import SeqIO\n",
    "from IPython.display import HTML\n",
    "from onecodex.notebooks.report import set_style, title\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path(os.environ.get(\"RESULTS_DIR\", os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "MIN_DEPTH = int(os.environ.get(\"MIN_DEPTH\", 50))\n",
    "# no longer needed?\n",
    "SEQUENCING_PLATFORM = os.getenv(\"SEQUENCING_PLATFORM\", \"Oxford Nanopore\")\n",
    "\n",
    "SAMPLE_PATH = glob(str(RESULTS_DIR / \"*.fastq.gz\"))[0]\n",
    "\n",
    "# outputs of bioinformatics pipeline (default paths)\n",
    "VARIANTS_VCF_PATH = RESULTS_DIR / \"variants.vcf\"\n",
    "NEXTCLADE_JSON = RESULTS_DIR / \"nextclade.json\"\n",
    "NEXTCLADE_TSV_PATH = RESULTS_DIR / \"nextclade.tsv\"\n",
    "PANGOLIN_CSV_PATH = RESULTS_DIR / \"pangolin.csv\"\n",
    "CONSENSUS_PATH = RESULTS_DIR / \"consensus.fa\"\n",
    "SNPS_DEPTH_PATH = RESULTS_DIR / \"snps.depth\"\n",
    "\n",
    "\n",
    "# databases\n",
    "REFERENCE_PATH = os.environ.get(\"FASTA_REFERENCE\", \"/share/nCoV-2019.reference.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes this is slow but it doesn't require an API call\n",
    "# (but it would be nice to not need the fastq as this point maybe. maybe this is in the bam file?)\n",
    "total_reads = 0\n",
    "with gzip.open(SAMPLE_PATH, \"rt\") as handle:\n",
    "    for line in handle:\n",
    "        total_reads += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference genome\n",
    "reference = list(SeqIO.parse(CONSENSUS_PATH, \"fasta\"))\n",
    "reference_length = len(reference[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before proceeding, do QC on the consensus sequence.\n",
    "for record in SeqIO.parse(CONSENSUS_PATH, \"fasta\"):\n",
    "    if record.seq.count(\"N\") > 20000:\n",
    "        warning_messages.append(\n",
    "            \"The consensus sequence has too many ambiguous bases: \"\n",
    "            + str(record.seq.count(\"N\"))\n",
    "            + f\" N's against the {reference_length} base reference sequence.\"\n",
    "        )\n",
    "    runs = re.split(\n",
    "        r\"[^ATGC]\", str(record.seq)\n",
    "    )  # Split contig into unambiguous stretches\n",
    "    max_len = len(max(runs, key=len))  # Length of longest unambiguous stretch\n",
    "    if max_len < 10000:\n",
    "        warning_messages.append(\n",
    "            \"The consensus sequence is too incomplete for GISAID submission: the longest stretch of unambiguous bases is only \"\n",
    "            + str(max_len)\n",
    "            + \" bases (must be over 10,000).\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate before\n",
    "with open(RESULTS_DIR / \"total_mapped_reads.txt\") as handle:\n",
    "    total_mapped_reads = int(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_table = []\n",
    "\n",
    "with open(SNPS_DEPTH_PATH) as handle:\n",
    "    for line in handle:\n",
    "        row = line.strip().split(\"\\t\")\n",
    "        if len(row) == 1:\n",
    "            continue\n",
    "        depth_table.append(\n",
    "            {\"reference\": row[0], \"position\": int(row[1]), \"depth\": int(row[2])}\n",
    "        )\n",
    "depth_table = pd.DataFrame(depth_table, columns=[\"reference\", \"position\", \"depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate genome coverage (what percent of bases are coveraged at X coverage)\n",
    "# Use a fixed reference length that we use for `samtools depth` above\n",
    "\n",
    "covered_sites = set()\n",
    "covered_sites_mindepth = set()\n",
    "\n",
    "for _, row in depth_table.iterrows():\n",
    "    row = row.to_dict()\n",
    "    if row[\"depth\"] >= 1:\n",
    "        covered_sites.add(row[\"position\"])\n",
    "    if row[\"depth\"] >= MIN_DEPTH:\n",
    "        covered_sites_mindepth.add(row[\"position\"])\n",
    "\n",
    "cov = len(covered_sites) / reference_length\n",
    "if cov <= 0.9:\n",
    "    warning_messages.append(\n",
    "        \"The consensus sequence is too incomplete for GISAID submission (reads must span >90% of the reference).\"\n",
    "    )\n",
    "cov_mindepth = len(covered_sites_mindepth) / reference_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean over windows because altair can't handle > 5k points ...\n",
    "binned_depths = []\n",
    "window_width = reference_length // 4500\n",
    "\n",
    "for i in range(1, reference_length, window_width):\n",
    "    window = depth_table.loc[\n",
    "        (depth_table[\"position\"] > i) & (depth_table[\"position\"] < i + window_width)\n",
    "    ]\n",
    "\n",
    "    binned_depths.append(\n",
    "        {\"position\": i, \"depth\": window[\"depth\"].mean(),}\n",
    "    )\n",
    "\n",
    "binned_depths = pd.DataFrame(binned_depths)\n",
    "# Convert position from bp to kbp, to improve how the coverage plot looks\n",
    "binned_depths[\"position\"] = binned_depths[\"position\"]/1000\n",
    "mean_depth = depth_table[\"depth\"].mean() if not depth_table.empty else 0\n",
    "median_depth = depth_table[\"depth\"].median() if not depth_table.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Nextclade and Pangolin tables\n",
    "\n",
    "if not os.path.exists(PANGOLIN_CSV_PATH):\n",
    "    warning_messages.append(\"No pangolin output\")\n",
    "    have_pangolin = False\n",
    "else:\n",
    "    have_pangolin = True\n",
    "    pangolin_table = pd.read_csv(PANGOLIN_CSV_PATH, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nextclade JSON\n",
    "##### Please note that everything in the Nextclade JSON (nt positions, ranges, codon positions) is 0-indexed,\n",
    "##### but SARS-CoV-2 variants (and most things) are reported as 1-indexed.\n",
    "\n",
    "with open(NEXTCLADE_JSON) as json_file:\n",
    "    nextclade_json = json.load(json_file)\n",
    "    assert len(nextclade_json) == 1, f\"expected exactly 1 result in: {nextclade_json}\"\n",
    "    nextclade_json = nextclade_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(nextclade_json[\"errors\"]) > 0:\n",
    "    have_nextclade = False\n",
    "    nextclade_lineage = None\n",
    "    warning_messages.extend(nextclade_json[\"errors\"])\n",
    "    n_snps_mindepth = None\n",
    "    n_snps = None\n",
    "    nextclade_pm_count = None\n",
    "elif len(nextclade_json['substitutions']) == 0:\n",
    "    warning_messages.append(\"No variants detected\")\n",
    "    have_nextclade = True\n",
    "    nextclade_lineage = None\n",
    "    n_snps_mindepth = 0\n",
    "    n_snps = 0\n",
    "    nextclade_pm_count = 0\n",
    "else:\n",
    "    have_nextclade = True\n",
    "    # Generate warnings if indels are detected? (ONT does not reliably detect these)\n",
    "    if nextclade_json[\"insertions\"] != []:\n",
    "        warning_messages.append(\"Insertions are detected.\")\n",
    "    if nextclade_json[\"deletions\"] != []:\n",
    "        warning_messages.append(\"Deletions are detected.\")\n",
    "\n",
    "    # load nextclade JSON\n",
    "    rows_list = []\n",
    "    for subst in nextclade_json[\"substitutions\"]:  # Each substitution is a dictionary\n",
    "        dict1 = {}\n",
    "        dict1[\"Position\"] = (\n",
    "            subst[\"pos\"] + 1\n",
    "        )  # JSON positions are 0-indexed; convert to 1-index\n",
    "        dict1[\"Ref\"] = subst[\"refNuc\"]\n",
    "        dict1[\"Alt\"] = subst[\"queryNuc\"]\n",
    "        if len(subst[\"aaSubstitutions\"]) != 0:\n",
    "            for mutation in subst[\n",
    "                \"aaSubstitutions\"\n",
    "            ]:  # JSON codons are 0-indexed; convert to 1-index\n",
    "                dict1[\"Amino acid mutation\"] = (\n",
    "                    mutation[\"refAA\"] + str(mutation[\"codon\"] + 1) + mutation[\"queryAA\"]\n",
    "                )\n",
    "        else:\n",
    "            dict1[\"Amino acid mutation\"] = \"\"\n",
    "        rows_list.append(dict1)\n",
    "\n",
    "    df_nextclade = pd.DataFrame(rows_list)\n",
    "    # in case mutations are outside of Genes\n",
    "    df_nextclade['Gene'] = '-'\n",
    "    \n",
    "    # load variants VCF\n",
    "    df_vcf = pd.read_csv(\n",
    "        VARIANTS_VCF_PATH,\n",
    "        comment=\"#\",\n",
    "        sep=\"\\t\",\n",
    "        usecols=[1, 7],\n",
    "        names=[\"position\", \"info\"],\n",
    "        index_col=[\"position\"],\n",
    "    )\n",
    "    \n",
    "    # Add in gene info\n",
    "    df_orfs = pd.read_csv(\n",
    "        \"./annot_table.orfs.txt\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[\"gene\", \"start\", \"stop\"],\n",
    "    )\n",
    "    \n",
    "    # join nextclade, VCF data and ORF annotations\n",
    "\n",
    "    for i in df_nextclade.index:\n",
    "        for j in df_orfs.index:\n",
    "            if (\n",
    "                df_orfs.loc[j, \"start\"]\n",
    "                <= df_nextclade.loc[i, \"Position\"]\n",
    "                <= df_orfs.loc[j, \"stop\"]\n",
    "            ):\n",
    "                df_nextclade.loc[i, \"Gene\"] = df_orfs.loc[j, \"gene\"]\n",
    "\n",
    "    # df_nextclade in depth info\n",
    "    variant_table = df_nextclade.set_index(\"Position\")\n",
    "\n",
    "    # parse site depth from info column\n",
    "    sr = [\n",
    "        [int(n) for n in x[1].split(\";\")[0].split(\",\")]\n",
    "        for x in df_vcf[\"info\"].str.rsplit(\";SR=\")\n",
    "    ]\n",
    "\n",
    "    assert {len(x) for x in sr} == {4}\n",
    "\n",
    "    df_vcf[\"Ref depth\"] = [sum(n[:2]) for n in sr]\n",
    "    df_vcf[\"Alt depth\"] = [sum(n[2:]) for n in sr]\n",
    "    df_vcf[\"Total depth\"] = df_vcf[\"Ref depth\"] + df_vcf[\"Alt depth\"]\n",
    "\n",
    "    # sum depths between multiple pools\n",
    "    summed = (\n",
    "        df_vcf.reset_index()[[\"position\", \"Ref depth\", \"Alt depth\", \"Total depth\"]]\n",
    "        .groupby(\"position\")\n",
    "        .agg(sum)\n",
    "    )\n",
    "\n",
    "    summed[\"Alt frequency (%)\"] = (\n",
    "        summed[\"Alt depth\"] / (summed[\"Alt depth\"] + summed[\"Ref depth\"]) * 100\n",
    "    )\n",
    "\n",
    "    pd.options.display.float_format = \"{:,.2f}\".format\n",
    "    variants_table = variant_table.merge(\n",
    "        summed, left_index=True, right_index=True, how=\"left\"\n",
    "    )\n",
    "\n",
    "    variants_table = variants_table[\n",
    "        [\n",
    "            \"Ref\",\n",
    "            \"Alt\",\n",
    "            \"Alt depth\",\n",
    "            \"Total depth\",\n",
    "            \"Alt frequency (%)\",\n",
    "            \"Gene\",\n",
    "            \"Amino acid mutation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    n_snps = variants_table.shape[0]\n",
    "    n_snps_mindepth = sum(variants_table[\"Total depth\"] > MIN_DEPTH)\n",
    "\n",
    "    nextclade_pm_count = nextclade_json[\"qc\"][\"privateMutations\"][\"total\"]\n",
    "    nextclade_lineage = nextclade_json[\"clade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if have_pangolin:\n",
    "    pangolin_lineage = pangolin_table[\"lineage\"].iloc[0]\n",
    "    pangolin_version = pangolin_table[\"pangoLEARN_version\"].iloc[0]\n",
    "else:\n",
    "    warning_messages.append(\"Pangolin failed\")\n",
    "    pangolin_lineage = \"Undetected or error\"\n",
    "    pangolin_version = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"SARS-CoV-2 (COVID-19) Sequencing Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "This report summarizes the detection of SARS-CoV-2 single-nucleotide variants (SNVs) in sample \n",
    "<strong>{os.path.basename(SAMPLE_PATH)}</strong>.\n",
    "\n",
    "<p>A minimum depth of 50x was chosen for confident SNV detection based on <a href=\"https://doi.org/10.1038/s41467-020-20075-6\">benchmarking</a> of SARS-CoV-2 sequencing data generated with ARTIC network amplicon protocols and ONT sequencing. This benchmarking study also concludes that ONT sequencing is unsuitable for detection of small indel varants, which we do no report here.\n",
    "\n",
    "<p>This sample contained <strong>{total_reads:,}</strong> reads, with\n",
    "<strong>{total_mapped_reads / total_reads:.1%}</strong> mapping to the \n",
    "<a href='https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3/' target='_blank'>Wuhan-Hu-1 reference</a>.\n",
    "Reads span <strong>{cov:.0%}</strong> of the genome, with a mean depth of <strong>{mean_depth:.0f}x</strong>, and {cov_mindepth:.0%} of the genome covered at depths >{MIN_DEPTH:}x.</p>\n",
    "\n",
    "<p>A total of <strong>{n_snps_mindepth}</strong> variant{'s were' if n_snps_mindepth != 1 else 'was'} detected at depths >{MIN_DEPTH:}x.\n",
    "This genome is classified as Pangolin lineage <strong>{pangolin_lineage}</strong> using PangoLEARN version {pangolin_version} and Nextclade lineage <strong>{nextclade_lineage}</strong> with {nextclade_pm_count} private mutation{'s' if nextclade_pm_count != 1 else ''}.</p>\"\"\"\n",
    "\n",
    "HTML(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage plot\n",
    "reference_length_kb = reference_length // 1000\n",
    "\n",
    "plot = (\n",
    "    alt.Chart(binned_depths)\n",
    "    .mark_area()\n",
    "    .transform_window(rolling_mean=\"mean(depth)\", frame=[-50, 50])\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"position\",\n",
    "            title=\"Genomic Coordinate (kb)\",\n",
    "            scale=alt.Scale(domain=[0, reference_length_kb]),\n",
    "        ),\n",
    "        y=alt.Y(\"rolling_mean:Q\", scale=alt.Scale(type=\"linear\"), title=\"Depth\"),\n",
    "    )\n",
    "    .properties(\n",
    "        title=f\"SARS-CoV-2\",\n",
    "        width=550,\n",
    "        height=150,\n",
    "    )\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_snps_mindepth is None:\n",
    "    display(HTML(\"Nextclade Error. See Warnings below.\"))\n",
    "elif n_snps_mindepth > 0: # If there are variants\n",
    "    display(variants_table[variants_table['Total depth'] > MIN_DEPTH])\n",
    "    legend_text = \"SARS-CoV-2 variants.\"\n",
    "\n",
    "    n_extra_variants = (\n",
    "        sum(variants_table[\"Total depth\"] > MIN_DEPTH) if not variant_table.empty else 0\n",
    "    )\n",
    "\n",
    "    if n_extra_variants > 0:\n",
    "        legend_text += f\" An additional {n_extra_variants} variant{'s' if n_extra_variants > 1 else ''} <{MIN_DEPTH}Ã— depth {'are' if n_extra_variants > 1 else 'is'} not shown.\"\n",
    "\n",
    "\n",
    "    if os.environ.get(\"ONE_CODEX_REPORT_UUID\"):\n",
    "        legend_text += f\"\"\" \n",
    "             A variants TSV and consensus FASTA is available <a target=\"_blank\" href=\\\"{'https://app.onecodex.com/report/' + os.environ['ONE_CODEX_REPORT_UUID'] + '/files'}\\\">here</a>.\n",
    "            \"\"\"\n",
    "    display(HTML(\n",
    "        '<div style=\"text-align: center; padding-top: 10px; font-size: 0.7em; color: #777;\"><em>'\n",
    "        + legend_text\n",
    "        + \"</em></div>\"\n",
    "    ))\n",
    "else:\n",
    "    HTML(f\"No variants detected > {MIN_DEPTH}-x depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- Additional bioinformatics pipeline details are [available on GitHub](https://github.com/onecodex/sars-cov-2)\n",
    "- [Nextstrain](https://nextstrain.org/ncov) maintains an up-to-date analysis of SARS-CoV-2 (HCoV-19).\n",
    "- The [Global Initiative on Sharing All Influenza Data (GISAID)](https://www.gisaid.org/) hosts viral genomes from ongoing outbreaks. Please [contact us](mailto:hello@onecodex.com) for help submitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add One Codex report ID to footer for reproducibility/data provenance (not yet in v0.7.2)\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "<style type='text/css'>\n",
    "@page {{\n",
    "    @bottom-center {{\n",
    "        content: \"{os.environ['ONE_CODEX_REPORT_UUID'] + ' -' if os.environ.get('ONE_CODEX_REPORT_UUID') else ''} NOT FOR DIAGNOSTIC USE\" !important;\n",
    "    }}\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a JSON too, including filtered variants <50x\n",
    "results = {\n",
    "    \"n_reads\": total_reads,\n",
    "    \"n_mapped_reads\": total_mapped_reads,\n",
    "    \"report_id\": os.environ.get(\"ONE_CODEX_REPORT_UUID\"), \n",
    "    \"sample_id\": os.environ.get(\"ONE_CODEX_SAMPLE_UUID\"),\n",
    "    \"variants\": variants_table.to_dict(orient='records') if n_snps else None,\n",
    "    \"coverage\": cov,\n",
    "    \"coverage_over_50x\": cov_mindepth,\n",
    "    \"mean_depth\": mean_depth,\n",
    "    \"median_depth\": median_depth,\n",
    "    \"nextclade_results\": nextclade_json,\n",
    "    \"pangolin_lineage\": pangolin_lineage,\n",
    "    \"nextclade_lineage\": nextclade_lineage,\n",
    "    \"warnings\": warning_messages,\n",
    "}\n",
    "\n",
    "with gzip.open(f\"{os.path.basename(SAMPLE_PATH)}.report.json.gz\", \"w\") as f:\n",
    "    f.write(json.dumps(results).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(warning_messages) > 0:\n",
    "    display(HTML(\"<ul>\"))\n",
    "    display(HTML(\"<h1>Warning Messages</h1>\"))    \n",
    "    for message in warning_messages:\n",
    "        display(HTML(f\"<li>{message}</li>\"))\n",
    "    display(HTML(\"</ul>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
